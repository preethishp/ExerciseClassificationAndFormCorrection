{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNNO3t6Dte9cHPsYgR02IB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preethishp/ExerciseClassificationAndFormCorrection/blob/main/AIBasedExerciseRecognitionAndFormCorrection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "LrOw7cotjaut",
        "outputId": "64e851d8-7e8d-4091-b767-a0717a6f9c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ed02e2d-0ca4-45f1-94fe-34509cd1aa38\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8ed02e2d-0ca4-45f1-94fe-34509cd1aa38\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"preethishp\",\"key\":\"40ff96159a26942305cddf86dca2d421\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S325Nsrni-Tc",
        "outputId": "a8b85f9f-e102-452f-8cff-d2724798cd0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/hasyimabdillah/workoutfitness-video\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading workoutfitness-video.zip to /content/workout\n",
            "100% 4.31G/4.32G [00:47<00:00, 149MB/s]\n",
            "100% 4.32G/4.32G [00:47<00:00, 98.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download & unzip the dataset (hasyimabdillah/workoutfitness-video)\n",
        "!kaggle datasets download -d hasyimabdillah/workoutfitness-video -p /content/workout --unzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -altr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbgoeXSg8VIz",
        "outputId": "de99119b-d5e4-4deb-9ca8-4192cc3bd373"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16\n",
            "drwxr-xr-x 4 root root 4096 Aug 28 13:42 .config\n",
            "drwxr-xr-x 1 root root 4096 Aug 28 13:42 .\n",
            "drwxr-xr-x 1 root root 4096 Aug 28 13:43 sample_data\n",
            "drwxr-xr-x 1 root root 4096 Aug 31 20:29 ..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y mediapipe protobuf || true\n",
        "!pip install -q ultralytics opencv-python tqdm\n",
        "import torch, cv2, numpy as np\n",
        "from ultralytics import YOLO\n",
        "print(\"Ultralytics ready. Torch:\", torch.__version__)"
      ],
      "metadata": {
        "id": "Ve_Jsasbi_EU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7541f8-ae56-4620-9e88-8fc79cf207b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping mediapipe as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: protobuf 5.29.5\n",
            "Uninstalling protobuf-5.29.5:\n",
            "  Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "✅ Ultralytics ready. Torch: 2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load pose model\n",
        "pose_model = YOLO('yolov8n-pose.pt')\n",
        "\n",
        "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\", \".webm\"}\n",
        "EVERY_N_FRAMES = 2\n",
        "SEQ_MIN_FRAMES = 24\n",
        "\n",
        "LEFT_HIP, RIGHT_HIP = 11, 12\n",
        "FEATS = 17 * 2  # (x,y) for 17 kpts => 34\n",
        "\n",
        "def extract_pose_sequence_yolo(video_path, every_n=EVERY_N_FRAMES):\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    seq = []\n",
        "    fidx = 0\n",
        "    while cap.isOpened():\n",
        "        ok, frame = cap.read()\n",
        "        if not ok: break\n",
        "        if fidx % every_n == 0:\n",
        "            # Inference (return keypoints)\n",
        "            results = pose_model.predict(frame, verbose=False)\n",
        "            if not results or len(results[0].keypoints) == 0:\n",
        "                fidx += 1; continue\n",
        "\n",
        "            kps = results[0].keypoints  # N persons × 17 × 3 (x,y,conf)\n",
        "            # pick the person with the highest mean keypoint confidence\n",
        "            confs = kps.conf.squeeze(-1) if kps.conf.ndim == 3 else kps.conf  # (N,17)\n",
        "            person_idx = torch.argmax(confs.mean(dim=1)).item()\n",
        "            xy = kps.xy[person_idx].cpu().numpy()  # (17,2) absolute pixels\n",
        "\n",
        "            # normalize by mid-hip to be camera-position invariant\n",
        "            lh, rh = xy[LEFT_HIP], xy[RIGHT_HIP]\n",
        "            origin = (lh + rh) / 2.0\n",
        "            xy_norm = (xy - origin)\n",
        "\n",
        "            seq.append(xy_norm.reshape(-1))  # (34,)\n",
        "        fidx += 1\n",
        "    cap.release()\n",
        "    if len(seq) == 0:\n",
        "        return np.zeros((0, FEATS), dtype=np.float32)\n",
        "    return np.asarray(seq, dtype=np.float32)  # (T,34)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhaAUusQ5wHq",
        "outputId": "1aba7566-24e1-4912-fc76-22b0225304c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-pose.pt to 'yolov8n-pose.pt': 100%|██████████| 6.52M/6.52M [00:00<00:00, 52.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = Path(\"/content/workout\")\n",
        "OUT  = Path(\"/content/pose_seq_yolo\")\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "items = []\n",
        "for p in ROOT.rglob(\"*\"):\n",
        "    if p.is_file() and p.suffix.lower() in VIDEO_EXTS:\n",
        "        label = p.parent.name\n",
        "        items.append((p, label))\n",
        "\n",
        "labels = sorted({lbl for _, lbl in items})\n",
        "label2id = {lbl:i for i,lbl in enumerate(labels)}\n",
        "print(\"Classes:\", labels)\n",
        "\n",
        "index = []\n",
        "for path, label in tqdm(items, desc=\"Pose->seq (YOLO)\"):\n",
        "    try:\n",
        "        arr = extract_pose_sequence_yolo(path)\n",
        "        if len(arr) < SEQ_MIN_FRAMES:\n",
        "            continue\n",
        "        out = OUT / f\"{label2id[label]:02d}__{path.stem}.npy\"\n",
        "        np.save(out, arr)\n",
        "        index.append((out, label2id[label]))\n",
        "    except Exception as e:\n",
        "        print(\"Skipping:\", path, e)\n",
        "\n",
        "len(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uDOcItO7LED",
        "outputId": "ea49d73b-fdc6-4589-e140-dcae8b3634d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pose->seq (YOLO): 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "9QoUsvRr7eS4",
        "outputId": "ebd28185-863e-4729-cf96-d36d40a0cd46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d16e25a2-efaa-4436-b5f4-5e9805d19044\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d16e25a2-efaa-4436-b5f4-5e9805d19044\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"preethishp\",\"key\":\"40ff96159a26942305cddf86dca2d421\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinstall protobuf (compatible version for Kaggle CLI)\n",
        "!pip install -q \"protobuf<4.0.0\"\n",
        "\n",
        "# Reinstall kaggle to make sure dependencies are correct\n",
        "!pip install -q --force-reinstall kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6nGGvJ99bm4",
        "outputId": "4a7b03d3-df22-4d4a-cb69-3fe46d7c9bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/162.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/162.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.32.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list -s workout | head -n 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdWb4jHN9K37",
        "outputId": "a77f8de7-a63c-46cf-bdea-3301bd4ab873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                              title                                                    size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "---------------------------------------------------------------  ------------------------------------------------  -----------  --------------------------  -------------  ---------  ---------------  \n",
            "hasyimabdillah/workoutfitness-video                              Workout/Exercises Video                            4641127680  2023-03-10 15:52:07.917000           6530         59  0.875            \n",
            "hasyimabdillah/workoutexercises-images                           Workout/Exercise Images                             857735926  2023-03-06 15:52:45.550000           2378         48  0.875            \n",
            "valakhorasani/gym-members-exercise-dataset                       Gym Members Exercise Dataset                            22093  2024-10-06 11:27:38.750000          40822        461  1.0              \n",
            "philosopher0808/gym-workoutexercises-video                       Gym Workout/Exercises Video                       10344292569  2024-05-12 04:02:38.817000           1094         26  0.625            \n",
            "joep89/weightlifting                                             721 Weight Training Workouts                            49030  2018-09-30 02:04:46.833000           2439         56  0.7647059        \n",
            "afsaja/workout-supplements-and-nutrition-products                Workout supplements and nutrition products              43143  2019-04-21 11:10:41.037000           1797         30  0.7058824        \n",
            "adnanelouardi/600k-fitness-exercise-and-workout-program-dataset  600K+ Fitness Exercise & Workout Program Dataset      6571966  2025-07-09 10:37:51.833000           1123         27  1.0              \n",
            "ruchikakumbhar/calories-burnt-prediction                         Calories Burnt Prediction                              241776  2025-01-20 06:00:34.450000           4588         64  1.0              \n",
            "govindaramsriram/sleep-time-prediction                           Sleep Time Prediction                                   28803  2024-12-28 17:08:56.653000           3169         41  1.0              \n",
            "nadeemajeedch/fitness-tracker-dataset                            Fitness Tracker Dataset                                 42931  2024-12-01 06:24:12.647000           2873         65  0.7058824        \n",
            "shakthisairam123/gym-workout-imu-dataset                         Gym Workout IMU Dataset                              66584047  2025-01-18 14:11:16.263000            526         30  0.9411765        \n",
            "drmkgray/workout-data                                            Workout Data                                        484536669  2021-01-12 01:53:03.847000            599         15  0.6875           \n",
            "andrew44456/workout-routes                                       Workout Routes                                        3755279  2022-09-05 07:28:27.147000            104          3  1.0              \n",
            "sumedh1507/fitness-and-workout-dataset                           Workout Preferences and Fitness Goals Dataset          385141  2025-07-19 06:25:41.733000            557         13  0.8235294        \n",
            "jiunn1998/workout-exercise                                       Workout Exercise                                   2912365980  2020-04-23 14:32:17.813000            606         20  0.4375           \n",
            "aniruddhaachar/audio-features                                    Audio Features for Playlist Creation                   313251  2017-03-03 06:23:55.113000           1147         37  0.8235294        \n",
            "rishitmurarka/gym-exercises-dataset                              Gym Exercises Dataset                                   49252  2024-07-31 09:27:00.493000           2033         37  0.88235295       \n",
            "tanisha1416/my-redmi-fuel-band-record-tracker-fitbit-dataset     Redmi Fuel Band Record Tracker (Fitbit Dataset)         32826  2022-02-23 09:35:57.893000            971         26  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oQi0uePm9Ric"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d hasyimabdillah/workoutfitness-video -p /content/data --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttnODZxu9zd2",
        "outputId": "8641b96b-a144-4d31-9c7d-03af168b6813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/hasyimabdillah/workoutfitness-video\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading workoutfitness-video.zip to /content/data\n",
            "100% 4.31G/4.32G [01:19<00:00, 43.1MB/s]\n",
            "100% 4.32G/4.32G [01:19<00:00, 58.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "def scan(root=Path(\"/content/data\")):\n",
        "    exts = Counter(p.suffix.lower() for p in root.rglob(\"*\") if p.is_file())\n",
        "    vids = [p for p in root.rglob(\"*\") if p.is_file() and p.suffix.lower() in {\".mp4\",\".mov\",\".avi\",\".mkv\",\".m4v\",\".webm\"}]\n",
        "    print(\"Root:\", root)\n",
        "    print(\"File extensions (top):\", exts.most_common(10))\n",
        "    print(\"Video count:\", len(vids))\n",
        "    for p in vids[:10]:\n",
        "        print(\" •\", p)\n",
        "    return root, vids\n",
        "\n",
        "ROOT, vids = scan(Path(\"/content/data\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK0gtkug9zTA",
        "outputId": "6dfdfbaf-e7d7-467b-fcff-59254234c873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root: /content/data\n",
            "File extensions (top): [('.mp4', 590), ('.mov', 62)]\n",
            "Video count: 652\n",
            " • /content/data/hammer curl/hammer curl_15.mp4\n",
            " • /content/data/hammer curl/hammer curl_6.MOV\n",
            " • /content/data/hammer curl/hammer curl_11.mp4\n",
            " • /content/data/hammer curl/hammer curl_18.mp4\n",
            " • /content/data/hammer curl/hammer curl_4.MOV\n",
            " • /content/data/hammer curl/hammer curl_2.MOV\n",
            " • /content/data/hammer curl/hammer curl_14.mp4\n",
            " • /content/data/hammer curl/hammer curl_5.MOV\n",
            " • /content/data/hammer curl/hammer curl_10.mp4\n",
            " • /content/data/hammer curl/hammer curl_17.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pathlib import Path\n",
        "ROOT = Path(\"/content/data\")\n",
        "OUT  = Path(\"/content/pose_seq_yolo\"); OUT.mkdir(parents=True, exist_ok=True)\n",
        "VIDEO_EXTS       = {\".mp4\",\".mov\",\".avi\",\".mkv\",\".m4v\",\".webm\"}\n",
        "EVERY_N_FRAMES   = 2\n",
        "SEQ_MIN_FRAMES   = 24\n",
        "SEQ_LEN          = 60\n",
        "FEATS            = 34\n",
        "BATCH_SIZE       = 8"
      ],
      "metadata": {
        "id": "A3klSSiC-piP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "items = []\n",
        "for p in ROOT.rglob(\"*\"):\n",
        "    if p.is_file() and p.suffix.lower() in VIDEO_EXTS:\n",
        "        label = p.parent.name\n",
        "        items.append((p, label))\n",
        "\n",
        "labels = sorted({lbl for _, lbl in items})\n",
        "label2id = {lbl:i for i,lbl in enumerate(labels)}\n",
        "print(f\"Discovered {len(items)} videos across {len(labels)} classes:\")\n",
        "print(labels[:50])\n",
        "assert len(items) > 0, \"No videos found – double-check ROOT path or unzip.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4d1-Ibf-xj5",
        "outputId": "cffc4f39-ab72-44ec-84d6-a7523e61adf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discovered 652 videos across 22 classes:\n",
            "['barbell biceps curl', 'bench press', 'chest fly machine', 'deadlift', 'decline bench press', 'hammer curl', 'hip thrust', 'incline bench press', 'lat pulldown', 'lateral raise', 'leg extension', 'leg raises', 'plank', 'pull Up', 'push-up', 'romanian deadlift', 'russian twist', 'shoulder press', 'squat', 't bar row', 'tricep Pushdown', 'tricep dips']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, numpy as np, torch\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "pose_model = YOLO(\"yolov8n-pose.pt\")\n",
        "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
        "pose_model.to(DEVICE)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    pose_model.model.half()\n",
        "\n",
        "LEFT_HIP, RIGHT_HIP = 11, 12\n",
        "LEFT_SHO, RIGHT_SHO = 5, 6\n",
        "\n",
        "def _preprocess_frame(frame, target=448):\n",
        "    h, w = frame.shape[:2]\n",
        "    if max(h, w) > target:\n",
        "        scale = target / max(h, w)\n",
        "        frame = cv2.resize(frame, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)\n",
        "    return frame\n",
        "\n",
        "def extract_pose_sequence_yolo_batched(video_path, every_n=3, batch_size=32, imgsz=448, conf=0.25):\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    frames = []\n",
        "    fidx = 0\n",
        "    while cap.isOpened():\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "        if fidx % every_n == 0:\n",
        "            frames.append(_preprocess_frame(frame, imgsz))\n",
        "        fidx += 1\n",
        "    cap.release()\n",
        "\n",
        "    if not frames:\n",
        "        return np.zeros((0, 34), dtype=np.float32)\n",
        "\n",
        "    seq = []\n",
        "    # Run in batches on GPU\n",
        "    for i in range(0, len(frames), batch_size):\n",
        "        batch = frames[i:i+batch_size]\n",
        "        results = pose_model.predict(\n",
        "            batch,\n",
        "            imgsz=imgsz,\n",
        "            device=DEVICE,\n",
        "            conf=conf,\n",
        "            max_det=1,\n",
        "            verbose=False\n",
        "        )\n",
        "        for res in results:\n",
        "            # If nothing detected, skip\n",
        "            if not hasattr(res, \"keypoints\") or res.keypoints is None or len(res.keypoints) == 0:\n",
        "                continue\n",
        "            # keypoints: (N, 17, 3) but N=1 with max_det=1\n",
        "            xy = res.keypoints.xy[0].float().cpu().numpy()  # (17,2)\n",
        "\n",
        "            # origin = mid-hip; scale = distance to mid-shoulder\n",
        "            origin = (xy[LEFT_HIP] + xy[RIGHT_HIP]) / 2.0\n",
        "            shoulder_mid = (xy[LEFT_SHO] + xy[RIGHT_SHO]) / 2.0\n",
        "            scale = np.linalg.norm(shoulder_mid - origin)\n",
        "            if scale < 1e-6:\n",
        "                scale = 1.0\n",
        "\n",
        "            xy_norm = (xy - origin) / scale\n",
        "            seq.append(xy_norm.reshape(-1))  # (34,)\n",
        "    if not seq:\n",
        "        return np.zeros((0, 34), dtype=np.float32)\n",
        "    return np.asarray(seq, dtype=np.float32)\n",
        "# Build items as (path, y_id) instead of (path, label_str)\n",
        "label2id = {lbl:i for i, lbl in enumerate(labels)}\n",
        "items_id = [(p, label2id[lbl]) for (p, lbl) in items]\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def process_one(args):\n",
        "    path, y_id = args  # y_id is int now\n",
        "    arr = extract_pose_sequence_yolo_batched(\n",
        "        path, every_n=EVERY_N_FRAMES, batch_size=32, imgsz=448, conf=0.25\n",
        "    )\n",
        "    if len(arr) >= SEQ_MIN_FRAMES:\n",
        "        out = OUT / f\"{y_id:02d}__{path.stem}.npy\"\n",
        "        np.save(out, arr)\n",
        "        return (out, y_id)\n",
        "    return None\n",
        "\n",
        "with Pool(min(4, cpu_count())) as pool:\n",
        "    results = list(tqdm(pool.imap(process_one, items_id, chunksize=2), total=len(items_id)))\n",
        "index = [r for r in results if r is not None]\n",
        "print(\"Cached sequences:\", len(index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iMbl_WV-0vm",
        "outputId": "f3c0ec0a-d0a9-4cc6-c51f-a9c054018168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 652/652 [1:59:58<00:00, 11.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cached sequences: 630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "\n",
        "\n",
        "SNAP_DIR = OUT\n",
        "META_DIR = SNAP_DIR\n",
        "INDEX_CSV = META_DIR / \"index.csv\"\n",
        "LABELS_JSON = META_DIR / \"labels.json\"\n",
        "\n",
        "def snapshot_cache(out_dir: Path, labels=None, label2id=None):\n",
        "    out_dir = Path(out_dir)\n",
        "    npys = sorted(out_dir.glob(\"*.npy\"))\n",
        "    entries = []\n",
        "    for f in npys:\n",
        "        m = re.match(r\"^(\\d+?)__.+?\\.npy$\", f.name)\n",
        "        if not m:\n",
        "            continue\n",
        "        y_id = int(m.group(1))\n",
        "        entries.append({\"seq_path\": str(f), \"label_id\": y_id})\n",
        "\n",
        "    df = pd.DataFrame(entries)\n",
        "    df.to_csv(out_dir / \"index.csv\", index=False)\n",
        "\n",
        "\n",
        "    meta = {}\n",
        "    if labels is not None:\n",
        "        meta[\"labels\"] = list(labels)\n",
        "    if label2id is not None:\n",
        "\n",
        "        meta[\"label2id\"] = {str(k): int(v) for k, v in label2id.items()}\n",
        "    if meta:\n",
        "        with open(out_dir / \"labels.json\", \"w\") as f:\n",
        "            json.dump(meta, f, indent=2)\n",
        "\n",
        "    print(f\"Snapshot saved: {out_dir/'index.csv'}\", end=\"\")\n",
        "    if meta:\n",
        "        print(f\" and {out_dir/'labels.json'}\")\n",
        "    else:\n",
        "        print(\" (no labels.json provided)\")\n",
        "\n",
        "try:\n",
        "    snapshot_cache(SNAP_DIR, labels=labels, label2id=label2id)\n",
        "except NameError:\n",
        "    snapshot_cache(SNAP_DIR, labels=None, label2id=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZErSDgkPmNG",
        "outputId": "59e65382-a826-4347-eb49-428bb65e380e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Snapshot saved: /content/pose_seq_yolo/index.csv and /content/pose_seq_yolo/labels.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np, torch, random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_CLASSES = len(labels)\n",
        "\n",
        "def pad_or_center_trim(x, T=SEQ_LEN):\n",
        "    t = len(x)\n",
        "    if t == T: return x\n",
        "    if t > T:\n",
        "        s = (t - T)//2\n",
        "        return x[s:s+T]\n",
        "    pad = np.zeros((T - t, x.shape[1]), dtype=x.dtype)\n",
        "    return np.concatenate([x, pad], axis=0)\n",
        "\n",
        "class PoseSeqDS(Dataset):\n",
        "    def __init__(self, entries): self.entries = entries\n",
        "    def __len__(self): return len(self.entries)\n",
        "    def __getitem__(self, i):\n",
        "        p, y = self.entries[i]\n",
        "        x = np.load(p)\n",
        "        x = pad_or_center_trim(x, SEQ_LEN)\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "random.seed(42)\n",
        "bylab = defaultdict(list)\n",
        "for p,y in index: bylab[y].append((p,y))\n",
        "train = []; val = []; test = []\n",
        "for y, L in bylab.items():\n",
        "    random.shuffle(L)\n",
        "    n=len(L); ntest=max(1,int(0.15*n)); nval=max(1,int(0.15*n))\n",
        "    test += L[:ntest]; val += L[ntest:ntest+nval]; train += L[ntest+nval:]\n",
        "\n",
        "train_dl = DataLoader(PoseSeqDS(train), batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_dl   = DataLoader(PoseSeqDS(val),   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_dl  = DataLoader(PoseSeqDS(test),  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "len(train), len(val), len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPRMqrd9-8Ei",
        "outputId": "659c01b4-2b15-4e53-abfe-3b42dff7cde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(460, 85, 85)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial LSTM model + training\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, feats=FEATS, hidden=128, layers=1, num_classes=NUM_CLASSES, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(feats, hidden, num_layers=layers, batch_first=True, dropout=0.0 if layers==1 else dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden, num_classes)\n",
        "    def forward(self, x):\n",
        "        _, (h, _) = self.lstm(x)\n",
        "        h = self.dropout(h[-1])\n",
        "        return self.fc(h)\n",
        "\n",
        "model = LSTMClassifier().to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def eval_loader(net, loader):\n",
        "    net.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            logits = net(xb)\n",
        "            loss_sum += criterion(logits, yb).item() * yb.size(0)\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    return loss_sum/max(total,1), correct/max(total,1)\n",
        "\n",
        "EPOCHS = 25\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running, batches = 0.0, 0\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        loss = criterion(model(xb), yb)\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        running += loss.item(); batches += 1\n",
        "    tr = running/max(batches,1)\n",
        "    vl, va = eval_loader(model, val_dl)\n",
        "    print(f\"Epoch {ep:02d} | train={tr:.4f} | val_loss={vl:.4f} | val_acc={va:.3f}\")\n",
        "\n",
        "tl, ta = eval_loader(model, test_dl)\n",
        "print(f\"🏁 Test: loss={tl:.4f} | acc={ta:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnzb6gRMOjt2",
        "outputId": "a78a607b-7c32-4802-b198-009a7de9cd8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train=2.9255 | val_loss=2.5670 | val_acc=0.212\n",
            "Epoch 02 | train=2.4445 | val_loss=2.2968 | val_acc=0.400\n",
            "Epoch 03 | train=2.3093 | val_loss=2.2186 | val_acc=0.353\n",
            "Epoch 04 | train=2.1133 | val_loss=1.9115 | val_acc=0.400\n",
            "Epoch 05 | train=1.8887 | val_loss=2.1875 | val_acc=0.282\n",
            "Epoch 06 | train=2.0765 | val_loss=1.8899 | val_acc=0.376\n",
            "Epoch 07 | train=1.9775 | val_loss=1.9106 | val_acc=0.365\n",
            "Epoch 08 | train=1.7340 | val_loss=1.6615 | val_acc=0.482\n",
            "Epoch 09 | train=1.9142 | val_loss=1.8131 | val_acc=0.424\n",
            "Epoch 10 | train=1.7760 | val_loss=1.8180 | val_acc=0.459\n",
            "Epoch 11 | train=1.8588 | val_loss=2.4749 | val_acc=0.259\n",
            "Epoch 12 | train=1.9032 | val_loss=1.7026 | val_acc=0.424\n",
            "Epoch 13 | train=1.6277 | val_loss=1.6885 | val_acc=0.435\n",
            "Epoch 14 | train=1.5610 | val_loss=1.5102 | val_acc=0.506\n",
            "Epoch 15 | train=1.7898 | val_loss=1.7554 | val_acc=0.447\n",
            "Epoch 16 | train=1.5107 | val_loss=1.4701 | val_acc=0.541\n",
            "Epoch 17 | train=1.5093 | val_loss=1.6090 | val_acc=0.576\n",
            "Epoch 18 | train=1.3981 | val_loss=1.4769 | val_acc=0.529\n",
            "Epoch 19 | train=1.4067 | val_loss=1.4007 | val_acc=0.565\n",
            "Epoch 20 | train=1.2695 | val_loss=1.3831 | val_acc=0.553\n",
            "Epoch 21 | train=1.2906 | val_loss=1.4007 | val_acc=0.541\n",
            "Epoch 22 | train=1.2125 | val_loss=1.3210 | val_acc=0.541\n",
            "Epoch 23 | train=1.1574 | val_loss=1.2513 | val_acc=0.576\n",
            "Epoch 24 | train=1.1067 | val_loss=1.2258 | val_acc=0.600\n",
            "Epoch 25 | train=1.0244 | val_loss=1.1662 | val_acc=0.624\n",
            "🏁 Test: loss=1.3768 | acc=0.576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# COCO indices\n",
        "LHIP, RHIP, LKNEE, RKNEE, LANK, RANK = 11,12,13,14,15,16\n",
        "LSHO, RSHO, LELB, RELB, LWR, RWR     = 5,6,7,8,9,10\n",
        "\n",
        "def angle_deg(a, b, c):\n",
        "    ba = a - b; bc = c - b\n",
        "    den = (np.linalg.norm(ba)*np.linalg.norm(bc))\n",
        "    if den == 0: return 180.0\n",
        "    cosv = np.clip(np.dot(ba,bc)/den, -1.0, 1.0)\n",
        "    return float(np.degrees(np.arccos(cosv)))\n",
        "\n",
        "def clip_stats(seq_xy):  # (T,34)\n",
        "    stats = {\"knee_r\":[], \"knee_l\":[], \"elbow_r\":[], \"elbow_l\":[]}\n",
        "    for t in range(len(seq_xy)):\n",
        "        xy = seq_xy[t].reshape(17,2)\n",
        "        stats[\"knee_r\"].append(angle_deg(xy[RHIP], xy[RKNEE], xy[RANK]))\n",
        "        stats[\"knee_l\"].append(angle_deg(xy[LHIP], xy[LKNEE], xy[LANK]))\n",
        "        stats[\"elbow_r\"].append(angle_deg(xy[RSHO], xy[RELB], xy[RWR]))\n",
        "        stats[\"elbow_l\"].append(angle_deg(xy[LSHO], xy[LELB], xy[LWR]))\n",
        "    return {k: {\"min\":float(np.min(v)), \"p90\":float(np.percentile(v,90))} for k,v in stats.items()}"
      ],
      "metadata": {
        "id": "Ev5gUE_SOnlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def collect_preds(model, loader):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            p = model(xb.to(DEVICE)).argmax(1).cpu().numpy()\n",
        "            preds.append(p); trues.append(yb.numpy())\n",
        "    return np.concatenate(preds), np.concatenate(trues)\n",
        "\n",
        "preds_val, y_val_np = collect_preds(model, val_dl)\n",
        "print(classification_report(y_val_np, preds_val, target_names=labels))\n",
        "print(confusion_matrix(y_val_np, preds_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teKCF6mYPq3r",
        "outputId": "c0fdf7f1-ba19-4264-8d7a-bc8733a7ec35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl       0.55      0.67      0.60         9\n",
            "        bench press       0.75      0.43      0.55         7\n",
            "  chest fly machine       0.67      0.50      0.57         4\n",
            "           deadlift       0.50      0.75      0.60         4\n",
            "decline bench press       0.00      0.00      0.00         1\n",
            "        hammer curl       0.00      0.00      0.00         2\n",
            "         hip thrust       1.00      1.00      1.00         2\n",
            "incline bench press       0.60      0.75      0.67         4\n",
            "       lat pulldown       0.50      0.71      0.59         7\n",
            "      lateral raise       0.29      0.40      0.33         5\n",
            "      leg extension       0.50      0.67      0.57         3\n",
            "         leg raises       0.00      0.00      0.00         3\n",
            "              plank       0.00      0.00      0.00         1\n",
            "            pull Up       0.60      1.00      0.75         3\n",
            "            push-up       0.78      0.88      0.82         8\n",
            "  romanian deadlift       1.00      0.50      0.67         2\n",
            "      russian twist       0.00      0.00      0.00         1\n",
            "     shoulder press       0.50      0.50      0.50         2\n",
            "              squat       0.33      0.25      0.29         4\n",
            "          t bar row       0.00      0.00      0.00         3\n",
            "    tricep Pushdown       0.67      0.86      0.75         7\n",
            "        tricep dips       1.00      0.33      0.50         3\n",
            "\n",
            "           accuracy                           0.56        85\n",
            "          macro avg       0.46      0.46      0.44        85\n",
            "       weighted avg       0.54      0.56      0.53        85\n",
            "\n",
            "[[6 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 3 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
            " [1 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 5 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 7 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, c): super().__init__(); self.c=c\n",
        "    def forward(self, x): return x[:, :, :-self.c].contiguous()\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_in, n_out, k, dilation, padding, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv1d(n_in, n_out, k, padding=padding, dilation=dilation),\n",
        "            nn.ReLU(), nn.Dropout(dropout), Chomp1d(padding),\n",
        "            nn.Conv1d(n_out, n_out, k, padding=padding, dilation=dilation),\n",
        "            nn.ReLU(), nn.Dropout(dropout), Chomp1d(padding),\n",
        "        )\n",
        "        self.down = nn.Conv1d(n_in, n_out, 1) if n_in!=n_out else nn.Identity()\n",
        "    def forward(self, x):\n",
        "        out = self.seq(x); return out + self.down(x)\n",
        "\n",
        "class TCNClassifier(nn.Module):\n",
        "    def __init__(self, feats=FEATS, channels=[64,64,128], k=5, dropout=0.2, num_classes=NUM_CLASSES):\n",
        "        super().__init__()\n",
        "        layers=[]; n_in=feats\n",
        "        for i, ch in enumerate(channels):\n",
        "            dil=2**i; pad=(k-1)*dil\n",
        "            layers.append(TemporalBlock(n_in, ch, k, dil, pad, dropout))\n",
        "            n_in=ch\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc   = nn.Linear(n_in, num_classes)\n",
        "    def forward(self, x):               # x: (B,T,F)\n",
        "        x = x.transpose(1,2)            # (B,F,T)\n",
        "        y = self.tcn(x)                 # (B,C,T)\n",
        "        y = self.pool(y).squeeze(-1)    # (B,C)\n",
        "        return self.fc(y)\n",
        "\n",
        "model = TCNClassifier().to(DEVICE)"
      ],
      "metadata": {
        "id": "s0IgAJhaQJ0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def eval_loader(net, loader):\n",
        "    net.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            logits = net(xb)\n",
        "            loss_sum += criterion(logits, yb).item() * yb.size(0)\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    return loss_sum/max(total,1), correct/max(total,1)\n",
        "\n",
        "EPOCHS = 25\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running, batches = 0.0, 0\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        loss = criterion(model(xb), yb)\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        running += loss.item(); batches += 1\n",
        "    tr = running/max(batches,1)\n",
        "    vl, va = eval_loader(model, val_dl)\n",
        "    print(f\"Epoch {ep:02d} | train={tr:.4f} | val_loss={vl:.4f} | val_acc={va:.3f}\")\n",
        "\n",
        "tl, ta = eval_loader(model, test_dl)\n",
        "print(f\"🏁 Test: loss={tl:.4f} | acc={ta:.3f}\")"
      ],
      "metadata": {
        "id": "yP1FWW0RqiY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b8b8dc-9330-4b0a-841d-a97aa0ee112d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train=0.2499 | val_loss=1.2686 | val_acc=0.765\n",
            "Epoch 02 | train=0.3573 | val_loss=1.3417 | val_acc=0.765\n",
            "Epoch 03 | train=0.3367 | val_loss=1.4739 | val_acc=0.765\n",
            "Epoch 04 | train=0.2957 | val_loss=1.3478 | val_acc=0.753\n",
            "Epoch 05 | train=0.1396 | val_loss=1.2850 | val_acc=0.788\n",
            "Epoch 06 | train=0.1262 | val_loss=1.3458 | val_acc=0.776\n",
            "Epoch 07 | train=0.1103 | val_loss=1.2177 | val_acc=0.765\n",
            "Epoch 08 | train=0.1434 | val_loss=1.3165 | val_acc=0.800\n",
            "Epoch 09 | train=0.1488 | val_loss=1.7329 | val_acc=0.765\n",
            "Epoch 10 | train=0.3369 | val_loss=1.4453 | val_acc=0.753\n",
            "Epoch 11 | train=0.3831 | val_loss=1.4063 | val_acc=0.776\n",
            "Epoch 12 | train=0.3813 | val_loss=1.4722 | val_acc=0.706\n",
            "Epoch 13 | train=0.3901 | val_loss=1.4782 | val_acc=0.706\n",
            "Epoch 14 | train=0.2430 | val_loss=1.2312 | val_acc=0.753\n",
            "Epoch 15 | train=0.0943 | val_loss=1.4995 | val_acc=0.812\n",
            "Epoch 16 | train=0.0489 | val_loss=1.5025 | val_acc=0.776\n",
            "Epoch 17 | train=0.0386 | val_loss=1.4289 | val_acc=0.800\n",
            "Epoch 18 | train=0.0296 | val_loss=1.5859 | val_acc=0.788\n",
            "Epoch 19 | train=0.0299 | val_loss=1.5292 | val_acc=0.776\n",
            "Epoch 20 | train=0.0970 | val_loss=1.2348 | val_acc=0.800\n",
            "Epoch 21 | train=0.1963 | val_loss=1.6726 | val_acc=0.706\n",
            "Epoch 22 | train=0.5636 | val_loss=2.5044 | val_acc=0.694\n",
            "Epoch 23 | train=0.6975 | val_loss=1.6729 | val_acc=0.741\n",
            "Epoch 24 | train=0.3487 | val_loss=1.3567 | val_acc=0.765\n",
            "Epoch 25 | train=0.2373 | val_loss=1.4877 | val_acc=0.800\n",
            "🏁 Test: loss=0.8928 | acc=0.812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def collect_preds(model, loader):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            p = model(xb.to(DEVICE)).argmax(1).cpu().numpy()\n",
        "            preds.append(p); trues.append(yb.numpy())\n",
        "    return np.concatenate(preds), np.concatenate(trues)\n",
        "\n",
        "preds_val, y_val_np = collect_preds(model, val_dl)\n",
        "print(classification_report(y_val_np, preds_val, target_names=labels))\n",
        "print(confusion_matrix(y_val_np, preds_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aK1JBEhpWgw",
        "outputId": "8c204237-3b05-4a20-df9e-4074945320eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl       0.82      1.00      0.90         9\n",
            "        bench press       0.62      0.71      0.67         7\n",
            "  chest fly machine       0.75      0.75      0.75         4\n",
            "           deadlift       1.00      0.75      0.86         4\n",
            "decline bench press       0.00      0.00      0.00         1\n",
            "        hammer curl       1.00      1.00      1.00         2\n",
            "         hip thrust       1.00      0.50      0.67         2\n",
            "incline bench press       1.00      0.50      0.67         4\n",
            "       lat pulldown       0.71      0.71      0.71         7\n",
            "      lateral raise       0.71      1.00      0.83         5\n",
            "      leg extension       0.75      1.00      0.86         3\n",
            "         leg raises       1.00      0.33      0.50         3\n",
            "              plank       1.00      1.00      1.00         1\n",
            "            pull Up       1.00      0.67      0.80         3\n",
            "            push-up       1.00      1.00      1.00         8\n",
            "  romanian deadlift       1.00      1.00      1.00         2\n",
            "      russian twist       0.50      1.00      0.67         1\n",
            "     shoulder press       0.67      1.00      0.80         2\n",
            "              squat       0.60      0.75      0.67         4\n",
            "          t bar row       1.00      1.00      1.00         3\n",
            "    tricep Pushdown       0.86      0.86      0.86         7\n",
            "        tricep dips       1.00      0.33      0.50         3\n",
            "\n",
            "           accuracy                           0.80        85\n",
            "          macro avg       0.82      0.77      0.76        85\n",
            "       weighted avg       0.83      0.80      0.79        85\n",
            "\n",
            "[[9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 5 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_tcn.py\n",
        "#!/usr/bin/env python3\n",
        "import argparse, os, json, random, re\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "# =========================\n",
        "# Repro\n",
        "# =========================\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# =========================\n",
        "# Sequence utils\n",
        "# =========================\n",
        "def pad_or_center_trim(x: np.ndarray, T: int) -> np.ndarray:\n",
        "    t = len(x)\n",
        "    if t == T: return x\n",
        "    if t > T:\n",
        "        s = (t - T)//2\n",
        "        return x[s:s+T]\n",
        "    pad = np.zeros((T - t, x.shape[1]), dtype=x.dtype)\n",
        "    return np.concatenate([x, pad], axis=0)\n",
        "\n",
        "LR_PAIRS = [(5,6),(7,8),(9,10),(11,12),(13,14),(15,16),(1,2),(3,4)]\n",
        "\n",
        "def horizontal_flip_sequence(x: np.ndarray) -> np.ndarray:\n",
        "    T, F = x.shape\n",
        "    xy = x.reshape(T, 17, 2).copy()\n",
        "    xy[..., 0] *= -1.0\n",
        "    for li, ri in LR_PAIRS:\n",
        "        tmp = xy[:, li, :].copy()\n",
        "        xy[:, li, :] = xy[:, ri, :]\n",
        "        xy[:, ri, :] = tmp\n",
        "    return xy.reshape(T, 34)\n",
        "\n",
        "def time_jitter(x: np.ndarray, drop_prob=0.04, dup_prob=0.04, target_len=60) -> np.ndarray:\n",
        "    out=[]\n",
        "    for i in range(len(x)):\n",
        "        if np.random.rand() < drop_prob:   # drop frame\n",
        "            continue\n",
        "        out.append(x[i])\n",
        "        if np.random.rand() < dup_prob and i+1 < len(x):\n",
        "            out.append(x[i])               # duplicate next\n",
        "    x = np.array(out, dtype=x.dtype)\n",
        "    return pad_or_center_trim(x, target_len)\n",
        "\n",
        "def time_mask(x: np.ndarray, prob=0.15, max_width=8) -> np.ndarray:\n",
        "    \"\"\"SpecAugment-style temporal masking: zero-out consecutive frames.\"\"\"\n",
        "    if prob <= 0 or max_width <= 0: return x\n",
        "    T = len(x)\n",
        "    m = x.copy()\n",
        "    if np.random.rand() < prob:\n",
        "        w = np.random.randint(1, max_width+1)\n",
        "        s = np.random.randint(0, max(1, T - w + 1))\n",
        "        m[s:s+w] = 0.0\n",
        "    return m\n",
        "\n",
        "# =========================\n",
        "# Dataset\n",
        "# =========================\n",
        "class PoseSeqDS(Dataset):\n",
        "    def __init__(self, entries, seq_len=60, training=False, use_aug=False,\n",
        "                 time_mask_prob=0.0, time_mask_max=0):\n",
        "        self.entries = entries\n",
        "        self.seq_len = seq_len\n",
        "        self.training = training\n",
        "        self.use_aug = use_aug\n",
        "        self.time_mask_prob = time_mask_prob\n",
        "        self.time_mask_max = time_mask_max\n",
        "\n",
        "    def __len__(self): return len(self.entries)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        p, y = self.entries[i]\n",
        "        x = np.load(p)\n",
        "        if self.training and self.use_aug:\n",
        "            x = time_jitter(x, 0.05, 0.05, self.seq_len)\n",
        "            if random.random() < 0.5:\n",
        "                x = horizontal_flip_sequence(x)\n",
        "        else:\n",
        "            x = pad_or_center_trim(x, self.seq_len)\n",
        "        if self.training and self.time_mask_prob > 0:\n",
        "            x = time_mask(x, self.time_mask_prob, self.time_mask_max)\n",
        "        x = torch.tensor(x, dtype=torch.float32)\n",
        "        y = torch.tensor(y, dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "# =========================\n",
        "# Discover cached data\n",
        "# =========================\n",
        "def discover_cache(cache_dir: Path):\n",
        "    cache_dir = Path(cache_dir)\n",
        "    index_csv = cache_dir / \"index.csv\"\n",
        "    labels_json = cache_dir / \"labels.json\"\n",
        "\n",
        "    index = []\n",
        "    if index_csv.exists():\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(index_csv)\n",
        "        for p, y in zip(df[\"seq_path\"], df[\"label_id\"]):\n",
        "            index.append((Path(p), int(y)))\n",
        "    else:\n",
        "        for f in sorted(cache_dir.glob(\"*.npy\")):\n",
        "            m = re.match(r\"^(\\d+?)__.+?\\.npy$\", f.name)\n",
        "            if m:\n",
        "                index.append((f, int(m.group(1))))\n",
        "\n",
        "    labels = []\n",
        "    label2id = {}\n",
        "    if labels_json.exists():\n",
        "        with open(labels_json) as f:\n",
        "            meta = json.load(f)\n",
        "        labels = meta.get(\"labels\", [])\n",
        "        label2id = {str(k): int(v) for k,v in meta.get(\"label2id\", {}).items()}\n",
        "    if not labels:\n",
        "        max_id = max((y for _,y in index), default=-1)\n",
        "        labels = [f\"class_{i:02d}\" for i in range(max_id+1)]\n",
        "        label2id = {name:i for i,name in enumerate(labels)}\n",
        "    return index, labels, label2id\n",
        "\n",
        "def stratified_split(index, val_frac=0.15, test_frac=0.15, seed=42):\n",
        "    random.seed(seed)\n",
        "    bylab = defaultdict(list)\n",
        "    for p,y in index: bylab[y].append((p,y))\n",
        "    train,val,test = [],[],[]\n",
        "    for y, L in bylab.items():\n",
        "        random.shuffle(L)\n",
        "        n = len(L)\n",
        "        n_test = max(1, int(round(test_frac*n)))\n",
        "        n_val  = max(1, int(round(val_frac*n)))\n",
        "        test  += L[:n_test]\n",
        "        val   += L[n_test:n_test+n_val]\n",
        "        train += L[n_test+n_val:]\n",
        "    return train,val,test\n",
        "\n",
        "# =========================\n",
        "# TCN\n",
        "# =========================\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, c): super().__init__(); self.c=c\n",
        "    def forward(self, x): return x[:, :, :-self.c].contiguous() if self.c>0 else x\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_in, n_out, k, dilation, padding, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv1d(n_in, n_out, k, padding=padding, dilation=dilation),\n",
        "            nn.ReLU(), nn.Dropout(dropout), Chomp1d(padding),\n",
        "            nn.Conv1d(n_out, n_out, k, padding=padding, dilation=dilation),\n",
        "            nn.ReLU(), nn.Dropout(dropout), Chomp1d(padding),\n",
        "        )\n",
        "        self.down = nn.Conv1d(n_in, n_out, 1) if n_in!=n_out else nn.Identity()\n",
        "    def forward(self, x):\n",
        "        out = self.seq(x)\n",
        "        return out + self.down(x)\n",
        "\n",
        "class TCNClassifier(nn.Module):\n",
        "    def __init__(self, feats=34, channels=(64,64,128), k=5, dropout=0.2, num_classes=10):\n",
        "        super().__init__()\n",
        "        layers=[]; n_in=feats\n",
        "        for i, ch in enumerate(channels):\n",
        "            dil = 2**i\n",
        "            pad = (k-1)*dil\n",
        "            layers.append(TemporalBlock(n_in, ch, k, dil, pad, dropout))\n",
        "            n_in = ch\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc   = nn.Linear(n_in, num_classes)\n",
        "    def forward(self, x):              # x: (B,T,F)\n",
        "        x = x.transpose(1,2)           # (B,F,T)\n",
        "        y = self.tcn(x)                # (B,C,T)\n",
        "        y = self.pool(y).squeeze(-1)   # (B,C)\n",
        "        return self.fc(y)\n",
        "\n",
        "# =========================\n",
        "# Loss / sampler\n",
        "# =========================\n",
        "def build_loss(use_class_weights, train_entries, num_classes, device, label_smoothing=0.0):\n",
        "    if use_class_weights:\n",
        "        counts = Counter([y for _,y in train_entries])\n",
        "        freq   = np.array([counts.get(i,0) for i in range(num_classes)], dtype=np.float32)\n",
        "        w = torch.tensor(1.0/np.maximum(freq,1), dtype=torch.float32, device=device)\n",
        "        w = w / w.mean()\n",
        "        return nn.CrossEntropyLoss(weight=w, label_smoothing=label_smoothing)\n",
        "    return nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "def build_sampler(use_sampler, train_entries, num_classes):\n",
        "    if not use_sampler: return None\n",
        "    counts = Counter([y for _,y in train_entries])\n",
        "    freq   = np.array([counts.get(i,0) for i in range(num_classes)], dtype=np.float32)\n",
        "    cw = 1.0/np.maximum(freq,1); cw = cw/ cw.mean()\n",
        "    weights = np.array([cw[y] for _,y in train_entries], dtype=np.float32)\n",
        "    return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "# =========================\n",
        "# Eval helpers\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def eval_loader(net, loader, device, criterion):\n",
        "    net.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = net(xb)\n",
        "        loss_sum += criterion(logits, yb).item() * yb.size(0)\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "    return loss_sum/max(total,1), correct/max(total,1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_preds(net, loader, device):\n",
        "    net.eval()\n",
        "    preds, trues = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device)\n",
        "        p = net(xb).argmax(1).cpu().numpy()\n",
        "        preds.append(p); trues.append(yb.numpy())\n",
        "    return np.concatenate(preds), np.concatenate(trues)\n",
        "\n",
        "# =========================\n",
        "# Pose-correction feedback\n",
        "# =========================\n",
        "LHIP,RHIP,LKNEE,RKNEE,LANK,RANK = 11,12,13,14,15,16\n",
        "LSHO,RSHO,LELB,RELB,LWR,RWR     = 5,6,7,8,9,10\n",
        "\n",
        "def angle_deg(a, b, c):\n",
        "    ba = a - b; bc = c - b\n",
        "    den = (np.linalg.norm(ba)*np.linalg.norm(bc))\n",
        "    if den == 0: return 180.0\n",
        "    cosv = np.clip(np.dot(ba,bc)/den, -1.0, 1.0)\n",
        "    return float(np.degrees(np.arccos(cosv)))\n",
        "\n",
        "def angles_from_seq(seq_xy: np.ndarray):\n",
        "    stats = {\"knee_r\":[], \"knee_l\":[], \"elbow_r\":[], \"elbow_l\":[]}\n",
        "    for t in range(len(seq_xy)):\n",
        "        xy = seq_xy[t].reshape(17,2)\n",
        "        stats[\"knee_r\"].append(angle_deg(xy[RHIP], xy[RKNEE], xy[RANK]))\n",
        "        stats[\"knee_l\"].append(angle_deg(xy[LHIP], xy[LKNEE], xy[LANK]))\n",
        "        stats[\"elbow_r\"].append(angle_deg(xy[RSHO], xy[RELB], xy[RWR]))\n",
        "        stats[\"elbow_l\"].append(angle_deg(xy[LSHO], xy[LELB], xy[LWR]))\n",
        "    return {k: {\n",
        "        \"min\": float(np.min(v)), \"max\": float(np.max(v)),\n",
        "        \"p10\": float(np.percentile(v,10)), \"p90\": float(np.percentile(v,90))\n",
        "    } for k,v in stats.items()}\n",
        "\n",
        "def feedback_from_stats(label: str, stats: dict):\n",
        "    label_l = (label or \"\").lower()\n",
        "    fb = []\n",
        "    if any(s in label_l for s in [\"squat\",\"leg extension\",\"hip thrust\"]):\n",
        "        knee_min = min(stats[\"knee_l\"][\"min\"], stats[\"knee_r\"][\"min\"])\n",
        "        if knee_min > 100: fb.append(\"Squat depth shallow — aim for ~90° knee flexion.\")\n",
        "        elif knee_min < 60: fb.append(\"Very deep — ensure control and comfort range.\")\n",
        "        else: fb.append(\"Good squat depth.\")\n",
        "    if any(s in label_l for s in [\"deadlift\",\"romanian\"]):\n",
        "        knee_min = min(stats[\"knee_l\"][\"min\"], stats[\"knee_r\"][\"min\"])\n",
        "        if knee_min < 70: fb.append(\"Knees bending a lot — hinge more from hips.\")\n",
        "    if any(s in label_l for s in [\"push\",\"press\",\"bench\"]):\n",
        "        emax = max(stats[\"elbow_l\"][\"p90\"], stats[\"elbow_r\"][\"p90\"])\n",
        "        if emax > 130: fb.append(\"Elbows flared — consider ~45° to protect shoulders.\")\n",
        "        else: fb.append(\"Elbow tracking looks reasonable.\")\n",
        "    if \"curl\" in label_l:\n",
        "        emin = min(stats[\"elbow_l\"][\"min\"], stats[\"elbow_r\"][\"min\"])\n",
        "        if emin > 80: fb.append(\"Limited elbow flexion — curl through fuller range.\")\n",
        "    if \"plank\" in label_l:\n",
        "        fb.append(\"Keep a straight line head→heels; avoid hip sag.\")\n",
        "    if not fb:\n",
        "        fb.append(\"Form looks okay; review depth and control.\")\n",
        "    return fb\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_feedback_on_file(npy_path: Path, model, labels, device, seq_len):\n",
        "    npy_path = Path(npy_path)\n",
        "    if not npy_path.exists():\n",
        "        print(f\"[analyze_npy] File not found: {npy_path}\")\n",
        "        return\n",
        "    seq = np.load(npy_path)\n",
        "    seq = pad_or_center_trim(seq, seq_len)\n",
        "    x = torch.tensor(seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    model.eval()\n",
        "    logits = model(x)\n",
        "    pred_id = int(logits.argmax(1).item())\n",
        "    pred_label = labels[pred_id] if 0 <= pred_id < len(labels) else str(pred_id)\n",
        "    print(f\"[analyze_npy] Predicted: {pred_label} (id={pred_id})\")\n",
        "    stats = angles_from_seq(seq)\n",
        "    cues = feedback_from_stats(pred_label, stats)\n",
        "    print(\"[feedback] angle stats:\", json.dumps(stats, indent=2))\n",
        "    print(\"[feedback] suggestions:\")\n",
        "    for c in cues: print(\" -\", c)\n",
        "\n",
        "# =========================\n",
        "# MixUp (loss-level, no label smoothing conflict)\n",
        "# =========================\n",
        "def mixup_batch(x, y, alpha=0.4):\n",
        "    if alpha <= 0: return x, y, None\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    index = torch.randperm(x.size(0), device=x.device)\n",
        "    x_mix = lam * x + (1 - lam) * x[index]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x_mix, (y_a, y_b), lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_mix):\n",
        "    y_a, y_b, lam = y_mix\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "# =========================\n",
        "# Main\n",
        "# =========================\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(\"Train TCN on cached pose sequences (+report, MixUp, time masking)\")\n",
        "    ap.add_argument(\"--cache_dir\", type=Path, required=True)\n",
        "    ap.add_argument(\"--seq_len\", type=int, default=60)\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=8)\n",
        "    ap.add_argument(\"--epochs\", type=int, default=25)\n",
        "    ap.add_argument(\"--lr\", type=float, default=3e-4)\n",
        "    ap.add_argument(\"--weight_decay\", type=float, default=1e-4)\n",
        "    ap.add_argument(\"--channels\", type=str, default=\"64,64,128\")\n",
        "    ap.add_argument(\"--kernel\", type=int, default=5)\n",
        "    ap.add_argument(\"--dropout\", type=float, default=0.2)\n",
        "    ap.add_argument(\"--use_aug\", action=\"store_true\")\n",
        "    ap.add_argument(\"--use_class_weights\", action=\"store_true\")\n",
        "    ap.add_argument(\"--use_sampler\", action=\"store_true\")\n",
        "    ap.add_argument(\"--label_smoothing\", type=float, default=0.0)\n",
        "    ap.add_argument(\"--scheduler\", type=str, default=\"cosine\", choices=[\"none\",\"cosine\"])\n",
        "    ap.add_argument(\"--patience\", type=int, default=6)\n",
        "    ap.add_argument(\"--save_path\", type=Path, default=Path(\"./best_tcn.pt\"))\n",
        "    ap.add_argument(\"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    ap.add_argument(\"--seed\", type=int, default=42)\n",
        "    ap.add_argument(\"--eval_only\", action=\"store_true\")\n",
        "    ap.add_argument(\"--checkpoint\", type=Path, default=None)\n",
        "    ap.add_argument(\"--analyze_npy\", type=Path, default=None)\n",
        "\n",
        "    # New flags\n",
        "    ap.add_argument(\"--report\", action=\"store_true\", help=\"print per-class report & confusion matrix\")\n",
        "    ap.add_argument(\"--report_path\", type=Path, default=None, help=\"optional CSV save dir for report/matrix\")\n",
        "    ap.add_argument(\"--mixup\", action=\"store_true\")\n",
        "    ap.add_argument(\"--mixup_alpha\", type=float, default=0.4)\n",
        "    ap.add_argument(\"--time_mask_prob\", type=float, default=0.0)\n",
        "    ap.add_argument(\"--time_mask_max\", type=int, default=0)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    set_seed(args.seed)\n",
        "\n",
        "    # Data\n",
        "    index, labels, label2id = discover_cache(args.cache_dir)\n",
        "    num_classes = len(labels)\n",
        "    if len(index) == 0:\n",
        "        raise SystemExit(f\"No sequences found in {args.cache_dir}\")\n",
        "\n",
        "    train, val, test = stratified_split(index, val_frac=0.15, test_frac=0.15, seed=args.seed)\n",
        "\n",
        "    pin = torch.cuda.is_available()\n",
        "    sampler = build_sampler(args.use_sampler, train, num_classes)\n",
        "    train_ds = PoseSeqDS(train, args.seq_len, True, args.use_aug, args.time_mask_prob, args.time_mask_max)\n",
        "    val_ds   = PoseSeqDS(val,   args.seq_len, False, False, 0.0, 0)\n",
        "    test_ds  = PoseSeqDS(test,  args.seq_len, False, False, 0.0, 0)\n",
        "\n",
        "    train_dl = DataLoader(train_ds, batch_size=args.batch_size,\n",
        "                          shuffle=(sampler is None), sampler=sampler,\n",
        "                          num_workers=2, pin_memory=pin)\n",
        "    val_dl   = DataLoader(val_ds,   batch_size=args.batch_size, shuffle=False, num_workers=2, pin_memory=pin)\n",
        "    test_dl  = DataLoader(test_ds,  batch_size=args.batch_size, shuffle=False, num_workers=2, pin_memory=pin)\n",
        "\n",
        "    # Model & training utils\n",
        "    channels = tuple(int(x) for x in args.channels.split(\",\") if x.strip())\n",
        "    model = TCNClassifier(feats=34, channels=channels, k=args.kernel, dropout=args.dropout,\n",
        "                          num_classes=num_classes).to(args.device)\n",
        "    criterion = build_loss(args.use_class_weights, train, num_classes, args.device, args.label_smoothing)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs) if args.scheduler==\"cosine\" else None\n",
        "\n",
        "    if args.checkpoint and Path(args.checkpoint).exists():\n",
        "        model.load_state_dict(torch.load(args.checkpoint, map_location=args.device))\n",
        "        print(f\"Loaded checkpoint: {args.checkpoint}\")\n",
        "\n",
        "    # Eval-only path\n",
        "    if args.eval_only:\n",
        "        vl, va = eval_loader(model, val_dl, args.device, criterion)\n",
        "        tl, ta = eval_loader(model, test_dl, args.device, criterion)\n",
        "        print(f\"[EvalOnly] val_loss={vl:.4f} val_acc={va:.3f} | test_loss={tl:.4f} test_acc={ta:.3f}\")\n",
        "        if args.report:\n",
        "            do_report(model, val_dl, test_dl, labels, args.device, args.report_path)\n",
        "        if args.analyze_npy:\n",
        "            run_feedback_on_file(args.analyze_npy, model, labels, args.device, args.seq_len)\n",
        "        return\n",
        "\n",
        "    # Train\n",
        "    best_val, bad = float(\"inf\"), 0\n",
        "    for ep in range(1, args.epochs+1):\n",
        "        model.train(); running=0.0; batches=0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(args.device), yb.to(args.device)\n",
        "            # MixUp (loss-level)\n",
        "            if args.mixup:\n",
        "                x_mix, y_mix, lam = mixup_batch(xb, yb, alpha=args.mixup_alpha)\n",
        "                logits = model(x_mix)\n",
        "                loss = mixup_criterion(criterion, logits, (y_mix[0], y_mix[1], lam))\n",
        "            else:\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "            running += loss.item(); batches += 1\n",
        "\n",
        "        tr = running/max(batches,1)\n",
        "        vl, va = eval_loader(model, val_dl, args.device, criterion)\n",
        "        if scheduler: scheduler.step()\n",
        "        print(f\"Epoch {ep:02d} | train={tr:.4f} | val_loss={vl:.4f} | val_acc={va:.3f}\")\n",
        "\n",
        "        if vl < best_val:\n",
        "            best_val, bad = vl, 0\n",
        "            torch.save(model.state_dict(), args.save_path)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= args.patience:\n",
        "                print(\"⏹️ Early stopping.\"); break\n",
        "\n",
        "    # Test best\n",
        "    model.load_state_dict(torch.load(args.save_path, map_location=args.device))\n",
        "    tl, ta = eval_loader(model, test_dl, args.device, criterion)\n",
        "    print(f\"🏁 Test(best): loss={tl:.4f} | acc={ta:.3f}\")\n",
        "\n",
        "    if args.report:\n",
        "        do_report(model, val_dl, test_dl, labels, args.device, args.report_path)\n",
        "\n",
        "    if args.analyze_npy:\n",
        "        run_feedback_on_file(args.analyze_npy, model, labels, args.device, args.seq_len)\n",
        "\n",
        "# =========================\n",
        "# Reporting\n",
        "# =========================\n",
        "def do_report(model, val_dl, test_dl, labels, device, out_dir=None):\n",
        "    try:\n",
        "        from sklearn.metrics import classification_report, confusion_matrix\n",
        "    except Exception:\n",
        "        print(\"scikit-learn not available; installing...\")\n",
        "        import subprocess, sys\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"scikit-learn\"])\n",
        "        from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "    pv, yv = collect_preds(model, val_dl, device)\n",
        "    pt, yt = collect_preds(model, test_dl, device)\n",
        "\n",
        "    print(\"\\n=== Validation Report ===\")\n",
        "    print(classification_report(yv, pv, target_names=labels, digits=3))\n",
        "    print(confusion_matrix(yv, pv))\n",
        "\n",
        "    print(\"\\n=== Test Report ===\")\n",
        "    print(classification_report(yt, pt, target_names=labels, digits=3))\n",
        "    cm = confusion_matrix(yt, pt)\n",
        "    print(cm)\n",
        "\n",
        "    if out_dir:\n",
        "        out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        import pandas as pd\n",
        "        # Save classification reports as CSV (per-split)\n",
        "        def report_to_df(y_true, y_pred):\n",
        "            from sklearn.metrics import precision_recall_fscore_support\n",
        "            p,r,f,s = precision_recall_fscore_support(y_true, y_pred, labels=list(range(len(labels))), zero_division=0)\n",
        "            return pd.DataFrame({\"label\": labels, \"precision\": p, \"recall\": r, \"f1\": f, \"support\": s})\n",
        "        report_to_df(yv, pv).to_csv(out_dir/\"val_report.csv\", index=False)\n",
        "        report_to_df(yt, pt).to_csv(out_dir/\"test_report.csv\", index=False)\n",
        "        pd.DataFrame(cm, index=labels, columns=labels).to_csv(out_dir/\"test_confusion_matrix.csv\", index=True)\n",
        "        print(f\"📁 Reports saved to: {out_dir}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSuJ2RtRpysk",
        "outputId": "bcdaa0f9-f54b-4f25-e8e9-a4452a50c470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_tcn.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_tcn.py --cache_dir /content/pose_seq_yolo \\\n",
        "  --epochs 25 --use_aug --use_class_weights \\\n",
        "  --mixup --mixup_alpha 0.4 \\\n",
        "  --time_mask_prob 0.15 --time_mask_max 8 \\\n",
        "  --report --save_path /content/best_tcn.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2ydXCNTrixR",
        "outputId": "efea4993-693d-4670-c33f-195d940b543d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train=3.0591 | val_loss=2.8526 | val_acc=0.242\n",
            "Epoch 02 | train=2.7724 | val_loss=2.4993 | val_acc=0.316\n",
            "Epoch 03 | train=2.4539 | val_loss=2.2049 | val_acc=0.368\n",
            "Epoch 04 | train=2.2369 | val_loss=2.0637 | val_acc=0.337\n",
            "Epoch 05 | train=2.2111 | val_loss=1.9934 | val_acc=0.400\n",
            "Epoch 06 | train=2.0564 | val_loss=1.8079 | val_acc=0.474\n",
            "Epoch 07 | train=1.9789 | val_loss=1.7255 | val_acc=0.400\n",
            "Epoch 08 | train=1.8966 | val_loss=1.9230 | val_acc=0.379\n",
            "Epoch 09 | train=1.9426 | val_loss=1.7095 | val_acc=0.442\n",
            "Epoch 10 | train=1.7579 | val_loss=1.6287 | val_acc=0.484\n",
            "Epoch 11 | train=1.8859 | val_loss=1.5490 | val_acc=0.547\n",
            "Epoch 12 | train=1.8561 | val_loss=1.5859 | val_acc=0.474\n",
            "Epoch 13 | train=1.7326 | val_loss=1.5802 | val_acc=0.526\n",
            "Epoch 14 | train=1.7660 | val_loss=1.5684 | val_acc=0.474\n",
            "Epoch 15 | train=1.7377 | val_loss=1.4501 | val_acc=0.547\n",
            "Epoch 16 | train=1.6827 | val_loss=1.4484 | val_acc=0.526\n",
            "Epoch 17 | train=1.6140 | val_loss=1.4054 | val_acc=0.558\n",
            "Epoch 18 | train=1.7450 | val_loss=1.3906 | val_acc=0.568\n",
            "Epoch 19 | train=1.5559 | val_loss=1.3641 | val_acc=0.579\n",
            "Epoch 20 | train=1.5575 | val_loss=1.3578 | val_acc=0.611\n",
            "Epoch 21 | train=1.4738 | val_loss=1.3395 | val_acc=0.600\n",
            "Epoch 22 | train=1.5088 | val_loss=1.3375 | val_acc=0.600\n",
            "Epoch 23 | train=1.5587 | val_loss=1.3336 | val_acc=0.589\n",
            "Epoch 24 | train=1.5082 | val_loss=1.3285 | val_acc=0.600\n",
            "Epoch 25 | train=1.6494 | val_loss=1.3284 | val_acc=0.600\n",
            "🏁 Test(best): loss=1.1508 | acc=0.663\n",
            "\n",
            "=== Validation Report ===\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl      0.600     0.333     0.429         9\n",
            "        bench press      1.000     0.429     0.600         7\n",
            "  chest fly machine      0.500     0.750     0.600         4\n",
            "           deadlift      0.333     0.400     0.364         5\n",
            "decline bench press      0.250     0.500     0.333         2\n",
            "        hammer curl      0.500     1.000     0.667         3\n",
            "         hip thrust      1.000     1.000     1.000         3\n",
            "incline bench press      0.250     0.250     0.250         4\n",
            "       lat pulldown      1.000     0.875     0.933         8\n",
            "      lateral raise      0.556     0.833     0.667         6\n",
            "      leg extension      1.000     0.500     0.667         4\n",
            "         leg raises      0.000     0.000     0.000         3\n",
            "              plank      0.000     0.000     0.000         1\n",
            "            pull Up      0.600     0.750     0.667         4\n",
            "            push-up      0.857     0.750     0.800         8\n",
            "  romanian deadlift      0.400     1.000     0.571         2\n",
            "      russian twist      1.000     1.000     1.000         2\n",
            "     shoulder press      0.667     0.667     0.667         3\n",
            "              squat      0.400     0.500     0.444         4\n",
            "          t bar row      0.000     0.000     0.000         3\n",
            "    tricep Pushdown      0.714     0.714     0.714         7\n",
            "        tricep dips      1.000     0.667     0.800         3\n",
            "\n",
            "           accuracy                          0.600        95\n",
            "          macro avg      0.574     0.587     0.553        95\n",
            "       weighted avg      0.643     0.600     0.594        95\n",
            "\n",
            "[[3 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 3 0 0 0 1 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 1 0 6 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 5 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2]]\n",
            "\n",
            "=== Test Report ===\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl      0.778     0.778     0.778         9\n",
            "        bench press      0.833     0.714     0.769         7\n",
            "  chest fly machine      0.600     0.750     0.667         4\n",
            "           deadlift      0.667     0.400     0.500         5\n",
            "decline bench press      0.000     0.000     0.000         2\n",
            "        hammer curl      0.500     0.667     0.571         3\n",
            "         hip thrust      1.000     0.333     0.500         3\n",
            "incline bench press      0.667     0.500     0.571         4\n",
            "       lat pulldown      1.000     0.750     0.857         8\n",
            "      lateral raise      0.667     0.667     0.667         6\n",
            "      leg extension      0.571     1.000     0.727         4\n",
            "         leg raises      0.667     0.667     0.667         3\n",
            "              plank      0.333     1.000     0.500         1\n",
            "            pull Up      0.667     0.500     0.571         4\n",
            "            push-up      0.857     0.750     0.800         8\n",
            "  romanian deadlift      0.500     1.000     0.667         2\n",
            "      russian twist      0.500     1.000     0.667         2\n",
            "     shoulder press      0.500     1.000     0.667         3\n",
            "              squat      0.750     0.750     0.750         4\n",
            "          t bar row      0.000     0.000     0.000         3\n",
            "    tricep Pushdown      0.556     0.714     0.625         7\n",
            "        tricep dips      1.000     0.333     0.500         3\n",
            "\n",
            "           accuracy                          0.663        95\n",
            "          macro avg      0.619     0.649     0.592        95\n",
            "       weighted avg      0.687     0.663     0.648        95\n",
            "\n",
            "[[7 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 5 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [1 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 1 0 6 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
            " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 5 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_tcn.py --cache_dir /content/pose_seq_yolo \\\n",
        "  --epochs 35 --batch_size 8 \\\n",
        "  --use_aug --use_class_weights --use_sampler \\\n",
        "  --mixup --mixup_alpha 0.3 \\\n",
        "  --time_mask_prob 0.10 --time_mask_max 12 \\\n",
        "  --label_smoothing 0.05 \\\n",
        "  --scheduler cosine --patience 10 \\\n",
        "  --seq_len 90 --channels 64,128,256 --kernel 7 \\\n",
        "  --report --report_path /content/tcn_reports \\\n",
        "  --save_path /content/best_tcn.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrBbghP4v4bz",
        "outputId": "6a22474f-daec-4ae4-b252-e47478a0107c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train=2.7115 | val_loss=3.3627 | val_acc=0.105\n",
            "Epoch 02 | train=2.2331 | val_loss=2.7081 | val_acc=0.242\n",
            "Epoch 03 | train=2.1067 | val_loss=2.5825 | val_acc=0.168\n",
            "Epoch 04 | train=1.8979 | val_loss=2.5084 | val_acc=0.232\n",
            "Epoch 05 | train=1.8633 | val_loss=2.5581 | val_acc=0.189\n",
            "Epoch 06 | train=1.7276 | val_loss=2.3701 | val_acc=0.274\n",
            "Epoch 07 | train=1.8104 | val_loss=2.2485 | val_acc=0.242\n",
            "Epoch 08 | train=1.5089 | val_loss=2.2910 | val_acc=0.316\n",
            "Epoch 09 | train=1.5474 | val_loss=2.2000 | val_acc=0.316\n",
            "Epoch 10 | train=1.5363 | val_loss=1.9979 | val_acc=0.421\n",
            "Epoch 11 | train=1.5638 | val_loss=2.1056 | val_acc=0.337\n",
            "Epoch 12 | train=1.5359 | val_loss=2.0524 | val_acc=0.400\n",
            "Epoch 13 | train=1.5344 | val_loss=2.0856 | val_acc=0.389\n",
            "Epoch 14 | train=1.5156 | val_loss=1.9244 | val_acc=0.474\n",
            "Epoch 15 | train=1.4428 | val_loss=1.9205 | val_acc=0.421\n",
            "Epoch 16 | train=1.3795 | val_loss=1.9190 | val_acc=0.484\n",
            "Epoch 17 | train=1.4324 | val_loss=1.9176 | val_acc=0.432\n",
            "Epoch 18 | train=1.2680 | val_loss=1.8103 | val_acc=0.474\n",
            "Epoch 19 | train=1.2391 | val_loss=1.7258 | val_acc=0.600\n",
            "Epoch 20 | train=1.1588 | val_loss=1.6635 | val_acc=0.600\n",
            "Epoch 21 | train=1.3135 | val_loss=1.7165 | val_acc=0.589\n",
            "Epoch 22 | train=1.2545 | val_loss=1.6202 | val_acc=0.653\n",
            "Epoch 23 | train=1.2423 | val_loss=1.6510 | val_acc=0.621\n",
            "Epoch 24 | train=1.1485 | val_loss=1.5682 | val_acc=0.642\n",
            "Epoch 25 | train=1.1945 | val_loss=1.6018 | val_acc=0.589\n",
            "Epoch 26 | train=1.2271 | val_loss=1.5768 | val_acc=0.663\n",
            "Epoch 27 | train=1.3526 | val_loss=1.6014 | val_acc=0.611\n",
            "Epoch 28 | train=1.2203 | val_loss=1.5870 | val_acc=0.611\n",
            "Epoch 29 | train=1.2104 | val_loss=1.5994 | val_acc=0.589\n",
            "Epoch 30 | train=1.1466 | val_loss=1.5512 | val_acc=0.632\n",
            "Epoch 31 | train=1.1087 | val_loss=1.5456 | val_acc=0.632\n",
            "Epoch 32 | train=1.1615 | val_loss=1.5421 | val_acc=0.621\n",
            "Epoch 33 | train=1.0679 | val_loss=1.5375 | val_acc=0.632\n",
            "Epoch 34 | train=1.2465 | val_loss=1.5351 | val_acc=0.632\n",
            "Epoch 35 | train=1.1531 | val_loss=1.5343 | val_acc=0.632\n",
            "🏁 Test(best): loss=1.3396 | acc=0.632\n",
            "\n",
            "=== Validation Report ===\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl      0.667     0.222     0.333         9\n",
            "        bench press      1.000     0.429     0.600         7\n",
            "  chest fly machine      0.750     0.750     0.750         4\n",
            "           deadlift      0.750     0.600     0.667         5\n",
            "decline bench press      0.500     0.500     0.500         2\n",
            "        hammer curl      0.333     1.000     0.500         3\n",
            "         hip thrust      0.750     1.000     0.857         3\n",
            "incline bench press      0.429     0.750     0.545         4\n",
            "       lat pulldown      1.000     0.375     0.545         8\n",
            "      lateral raise      0.833     0.833     0.833         6\n",
            "      leg extension      1.000     0.500     0.667         4\n",
            "         leg raises      0.375     1.000     0.545         3\n",
            "              plank      0.333     1.000     0.500         1\n",
            "            pull Up      0.429     0.750     0.545         4\n",
            "            push-up      1.000     0.625     0.769         8\n",
            "  romanian deadlift      0.500     1.000     0.667         2\n",
            "      russian twist      1.000     1.000     1.000         2\n",
            "     shoulder press      0.667     0.667     0.667         3\n",
            "              squat      0.500     0.250     0.333         4\n",
            "          t bar row      0.750     1.000     0.857         3\n",
            "    tricep Pushdown      0.667     0.857     0.750         7\n",
            "        tricep dips      1.000     0.333     0.500         3\n",
            "\n",
            "           accuracy                          0.632        95\n",
            "          macro avg      0.692     0.702     0.633        95\n",
            "       weighted avg      0.745     0.632     0.624        95\n",
            "\n",
            "[[2 0 0 0 0 5 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 1 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 3 0 0 1 0 2 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 2 0 5 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 6 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
            "\n",
            "=== Test Report ===\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl      0.857     0.667     0.750         9\n",
            "        bench press      1.000     0.286     0.444         7\n",
            "  chest fly machine      0.750     0.750     0.750         4\n",
            "           deadlift      1.000     0.400     0.571         5\n",
            "decline bench press      0.000     0.000     0.000         2\n",
            "        hammer curl      0.250     0.667     0.364         3\n",
            "         hip thrust      0.000     0.000     0.000         3\n",
            "incline bench press      0.500     0.750     0.600         4\n",
            "       lat pulldown      1.000     0.500     0.667         8\n",
            "      lateral raise      1.000     0.833     0.909         6\n",
            "      leg extension      0.800     1.000     0.889         4\n",
            "         leg raises      0.500     0.667     0.571         3\n",
            "              plank      0.200     1.000     0.333         1\n",
            "            pull Up      0.333     0.500     0.400         4\n",
            "            push-up      1.000     0.875     0.933         8\n",
            "  romanian deadlift      0.400     1.000     0.571         2\n",
            "      russian twist      0.400     1.000     0.571         2\n",
            "     shoulder press      0.600     1.000     0.750         3\n",
            "              squat      1.000     0.500     0.667         4\n",
            "          t bar row      0.500     0.333     0.400         3\n",
            "    tricep Pushdown      0.800     0.571     0.667         7\n",
            "        tricep dips      0.750     1.000     0.857         3\n",
            "\n",
            "           accuracy                          0.632        95\n",
            "          macro avg      0.620     0.650     0.576        95\n",
            "       weighted avg      0.742     0.632     0.635        95\n",
            "\n",
            "[[6 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 2 0 0 1 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 4 0 0 1 0 2 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 7 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
            " [1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 4 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]]\n",
            "📁 Reports saved to: /content/tcn_reports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_tcn.py --cache_dir /content/pose_seq_yolo \\\n",
        "  --epochs 30 --batch_size 8 \\\n",
        "  --use_aug --use_class_weights --use_sampler \\\n",
        "  --mixup --mixup_alpha 0.4 \\\n",
        "  --time_mask_prob 0.15 --time_mask_max 8 \\\n",
        "  --scheduler cosine --patience 8 \\\n",
        "  --report --report_path /content/tcn_reports \\\n",
        "  --save_path /content/best_tcn.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz-SEftfvEGZ",
        "outputId": "b9fe0128-e727-422e-c2f5-2fcbd2f8b3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train=2.9542 | val_loss=3.0629 | val_acc=0.042\n",
            "Epoch 02 | train=2.5669 | val_loss=2.7816 | val_acc=0.126\n",
            "Epoch 03 | train=2.2166 | val_loss=2.5918 | val_acc=0.179\n",
            "Epoch 04 | train=1.9424 | val_loss=2.3237 | val_acc=0.232\n",
            "Epoch 05 | train=1.9853 | val_loss=2.1394 | val_acc=0.284\n",
            "Epoch 06 | train=1.8343 | val_loss=1.9797 | val_acc=0.316\n",
            "Epoch 07 | train=1.7205 | val_loss=1.9446 | val_acc=0.274\n",
            "Epoch 08 | train=1.6631 | val_loss=1.8821 | val_acc=0.263\n",
            "Epoch 09 | train=1.6619 | val_loss=1.9026 | val_acc=0.295\n",
            "Epoch 10 | train=1.5073 | val_loss=1.8037 | val_acc=0.305\n",
            "Epoch 11 | train=1.6444 | val_loss=1.9205 | val_acc=0.316\n",
            "Epoch 12 | train=1.6016 | val_loss=1.8508 | val_acc=0.253\n",
            "Epoch 13 | train=1.4852 | val_loss=1.9791 | val_acc=0.326\n",
            "Epoch 14 | train=1.5401 | val_loss=1.8900 | val_acc=0.326\n",
            "Epoch 15 | train=1.5380 | val_loss=1.7546 | val_acc=0.347\n",
            "Epoch 16 | train=1.4474 | val_loss=1.7630 | val_acc=0.295\n",
            "Epoch 17 | train=1.3124 | val_loss=1.8281 | val_acc=0.347\n",
            "Epoch 18 | train=1.5410 | val_loss=1.7689 | val_acc=0.316\n",
            "Epoch 19 | train=1.3422 | val_loss=1.6655 | val_acc=0.358\n",
            "Epoch 20 | train=1.4452 | val_loss=1.6893 | val_acc=0.389\n",
            "Epoch 21 | train=1.4430 | val_loss=1.5820 | val_acc=0.442\n",
            "Epoch 22 | train=1.2588 | val_loss=1.6014 | val_acc=0.432\n",
            "Epoch 23 | train=1.3294 | val_loss=1.5953 | val_acc=0.442\n",
            "Epoch 24 | train=1.3374 | val_loss=1.5511 | val_acc=0.463\n",
            "Epoch 25 | train=1.3290 | val_loss=1.5935 | val_acc=0.421\n",
            "Epoch 26 | train=1.3428 | val_loss=1.5764 | val_acc=0.432\n",
            "Epoch 27 | train=1.3900 | val_loss=1.5653 | val_acc=0.463\n",
            "Epoch 28 | train=1.3763 | val_loss=1.5641 | val_acc=0.463\n",
            "Epoch 29 | train=1.3027 | val_loss=1.5642 | val_acc=0.453\n",
            "Epoch 30 | train=1.2901 | val_loss=1.5648 | val_acc=0.453\n",
            "🏁 Test(best): loss=1.3567 | acc=0.463\n",
            "\n",
            "=== Validation Report ===\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl      1.000     0.111     0.200         9\n",
            "        bench press      1.000     0.143     0.250         7\n",
            "  chest fly machine      0.500     0.500     0.500         4\n",
            "           deadlift      0.333     0.200     0.250         5\n",
            "decline bench press      0.400     1.000     0.571         2\n",
            "        hammer curl      0.214     1.000     0.353         3\n",
            "         hip thrust      1.000     1.000     1.000         3\n",
            "incline bench press      0.500     0.250     0.333         4\n",
            "       lat pulldown      1.000     0.625     0.769         8\n",
            "      lateral raise      0.667     0.667     0.667         6\n",
            "      leg extension      1.000     0.250     0.400         4\n",
            "         leg raises      0.333     0.667     0.444         3\n",
            "              plank      0.143     1.000     0.250         1\n",
            "            pull Up      0.400     0.500     0.444         4\n",
            "            push-up      1.000     0.250     0.400         8\n",
            "  romanian deadlift      0.400     1.000     0.571         2\n",
            "      russian twist      0.400     1.000     0.571         2\n",
            "     shoulder press      0.667     0.667     0.667         3\n",
            "              squat      0.667     0.500     0.571         4\n",
            "          t bar row      0.286     0.667     0.400         3\n",
            "    tricep Pushdown      0.667     0.286     0.400         7\n",
            "        tricep dips      0.250     0.333     0.286         3\n",
            "\n",
            "           accuracy                          0.463        95\n",
            "          macro avg      0.583     0.573     0.468        95\n",
            "       weighted avg      0.688     0.463     0.453        95\n",
            "\n",
            "[[1 0 0 0 0 6 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 1 1 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 1]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 5 0 0 0 0 1 0 0 1 1 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 6 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 2]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1]]\n",
            "\n",
            "=== Test Report ===\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl      1.000     0.111     0.200         9\n",
            "        bench press      0.000     0.000     0.000         7\n",
            "  chest fly machine      0.750     0.750     0.750         4\n",
            "           deadlift      0.500     0.200     0.286         5\n",
            "decline bench press      0.167     0.500     0.250         2\n",
            "        hammer curl      0.125     0.667     0.211         3\n",
            "         hip thrust      0.500     0.333     0.400         3\n",
            "incline bench press      0.667     0.500     0.571         4\n",
            "       lat pulldown      1.000     0.375     0.545         8\n",
            "      lateral raise      0.667     0.667     0.667         6\n",
            "      leg extension      0.600     0.750     0.667         4\n",
            "         leg raises      0.375     1.000     0.545         3\n",
            "              plank      0.167     1.000     0.286         1\n",
            "            pull Up      1.000     0.500     0.667         4\n",
            "            push-up      1.000     0.500     0.667         8\n",
            "  romanian deadlift      0.286     1.000     0.444         2\n",
            "      russian twist      0.400     1.000     0.571         2\n",
            "     shoulder press      0.600     1.000     0.750         3\n",
            "              squat      0.667     0.500     0.571         4\n",
            "          t bar row      0.000     0.000     0.000         3\n",
            "    tricep Pushdown      1.000     0.286     0.444         7\n",
            "        tricep dips      0.500     0.667     0.571         3\n",
            "\n",
            "           accuracy                          0.463        95\n",
            "          macro avg      0.544     0.559     0.457        95\n",
            "       weighted avg      0.646     0.463     0.455        95\n",
            "\n",
            "[[1 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 4 0 0 1 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 3 0 0 4 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 2 0 4 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 2 1]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]]\n",
            "📁 Reports saved to: /content/tcn_reports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_tcn.py --cache_dir /content/pose_seq_yolo \\\n",
        "  --eval_only --checkpoint /content/best_tcn.pt \\\n",
        "  --channels 64,128,256 --kernel 7 \\\n",
        "  --analyze_npy \"/content/pose_seq_yolo/14__push-up_36.npy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asIrPmOrrlVZ",
        "outputId": "81ca5ad9-dda7-4f95-c6a6-328ad123ce03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded checkpoint: /content/best_tcn.pt\n",
            "[EvalOnly] val_loss=1.5224 val_acc=0.526 | test_loss=1.3350 test_acc=0.526\n",
            "[analyze_npy] Predicted: push-up (id=14)\n",
            "[feedback] angle stats: {\n",
            "  \"knee_r\": {\n",
            "    \"min\": 0.8965660929679871,\n",
            "    \"max\": 148.65103149414062,\n",
            "    \"p10\": 18.443626308441164,\n",
            "    \"p90\": 142.558251953125\n",
            "  },\n",
            "  \"knee_l\": {\n",
            "    \"min\": 121.40056610107422,\n",
            "    \"max\": 161.4187774658203,\n",
            "    \"p10\": 123.7725212097168,\n",
            "    \"p90\": 153.2855712890625\n",
            "  },\n",
            "  \"elbow_r\": {\n",
            "    \"min\": 55.78034210205078,\n",
            "    \"max\": 169.14776611328125,\n",
            "    \"p10\": 87.44112701416016,\n",
            "    \"p90\": 166.6210693359375\n",
            "  },\n",
            "  \"elbow_l\": {\n",
            "    \"min\": 68.80013275146484,\n",
            "    \"max\": 146.9849090576172,\n",
            "    \"p10\": 73.56137542724609,\n",
            "    \"p90\": 142.16739807128906\n",
            "  }\n",
            "}\n",
            "[feedback] suggestions:\n",
            " - Elbows flared — consider ~45° to protect shoulders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_tcn.py\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "import argparse, json, random, re\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "# ------------------------- Repro -------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# -------------------- Sequence utilities ----------------\n",
        "def pad_or_center_trim(x: np.ndarray, T: int) -> np.ndarray:\n",
        "    t = len(x)\n",
        "    if t == T: return x\n",
        "    if t > T:\n",
        "        s = (t - T)//2\n",
        "        return x[s:s+T]\n",
        "    pad = np.zeros((T - t, x.shape[1]), dtype=x.dtype)\n",
        "    return np.concatenate([x, pad], axis=0)\n",
        "\n",
        "LR_PAIRS = [(5,6),(7,8),(9,10),(11,12),(13,14),(15,16),(1,2),(3,4)]\n",
        "\n",
        "def horizontal_flip_sequence(x: np.ndarray) -> np.ndarray:\n",
        "    T, F = x.shape\n",
        "    xy = x.reshape(T, 17, 2).copy()\n",
        "    xy[..., 0] *= -1.0\n",
        "    for li, ri in LR_PAIRS:\n",
        "        tmp = xy[:, li, :].copy()\n",
        "        xy[:, li, :] = xy[:, ri, :]\n",
        "        xy[:, ri, :] = tmp\n",
        "    return xy.reshape(T, 34)\n",
        "\n",
        "def time_jitter(x: np.ndarray, drop_prob=0.04, dup_prob=0.04, target_len=60) -> np.ndarray:\n",
        "    out=[]\n",
        "    for i in range(len(x)):\n",
        "        if np.random.rand() < drop_prob:   # drop\n",
        "            continue\n",
        "        out.append(x[i])\n",
        "        if np.random.rand() < dup_prob and i+1 < len(x):\n",
        "            out.append(x[i])               # dup\n",
        "    x = np.array(out, dtype=x.dtype)\n",
        "    return pad_or_center_trim(x, target_len)\n",
        "\n",
        "def time_mask(x: np.ndarray, prob=0.0, max_width=0) -> np.ndarray:\n",
        "    if prob <= 0 or max_width <= 0: return x\n",
        "    T = len(x)\n",
        "    m = x.copy()\n",
        "    if np.random.rand() < prob:\n",
        "        w = np.random.randint(1, max_width+1)\n",
        "        s = np.random.randint(0, max(1, T - w + 1))\n",
        "        m[s:s+w] = 0.0\n",
        "    return m\n",
        "\n",
        "# -------------------------- Dataset ----------------------\n",
        "class PoseSeqDS(Dataset):\n",
        "    def __init__(self, entries, seq_len=60, training=False, use_aug=False,\n",
        "                 time_mask_prob=0.0, time_mask_max=0):\n",
        "        self.entries = entries\n",
        "        self.seq_len = seq_len\n",
        "        self.training = training\n",
        "        self.use_aug = use_aug\n",
        "        self.time_mask_prob = time_mask_prob\n",
        "        self.time_mask_max = time_mask_max\n",
        "\n",
        "    def __len__(self): return len(self.entries)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        p, y = self.entries[i]\n",
        "        x = np.load(p)\n",
        "        if self.training and self.use_aug:\n",
        "            x = time_jitter(x, 0.05, 0.05, self.seq_len)\n",
        "            if random.random() < 0.5:\n",
        "                x = horizontal_flip_sequence(x)\n",
        "        else:\n",
        "            x = pad_or_center_trim(x, self.seq_len)\n",
        "        if self.training and self.time_mask_prob > 0:\n",
        "            x = time_mask(x, self.time_mask_prob, self.time_mask_max)\n",
        "        x = torch.tensor(x, dtype=torch.float32)\n",
        "        y = torch.tensor(y, dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "# --------------------- Data discovery/split ---------------\n",
        "def discover_cache(cache_dir: Path):\n",
        "    cache_dir = Path(cache_dir)\n",
        "    index_csv = cache_dir / \"index.csv\"\n",
        "    labels_json = cache_dir / \"labels.json\"\n",
        "\n",
        "    index = []\n",
        "    if index_csv.exists():\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(index_csv)\n",
        "        for p, y in zip(df[\"seq_path\"], df[\"label_id\"]):\n",
        "            index.append((Path(p), int(y)))\n",
        "    else:\n",
        "        for f in sorted(cache_dir.glob(\"*.npy\")):\n",
        "            m = re.match(r\"^(\\d+?)__.+?\\.npy$\", f.name)\n",
        "            if m:\n",
        "                index.append((f, int(m.group(1))))\n",
        "\n",
        "    labels, label2id = [], {}\n",
        "    if labels_json.exists():\n",
        "        with open(labels_json) as f:\n",
        "            meta = json.load(f)\n",
        "        labels = meta.get(\"labels\", [])\n",
        "        label2id = {str(k): int(v) for k,v in meta.get(\"label2id\", {}).items()}\n",
        "    if not labels:\n",
        "        max_id = max((y for _,y in index), default=-1)\n",
        "        labels = [f\"class_{i:02d}\" for i in range(max_id+1)]\n",
        "        label2id = {name:i for i,name in enumerate(labels)}\n",
        "    return index, labels, label2id\n",
        "\n",
        "def stratified_split(index, val_frac=0.15, test_frac=0.15, seed=42):\n",
        "    random.seed(seed)\n",
        "    bylab = defaultdict(list)\n",
        "    for p,y in index: bylab[y].append((p,y))\n",
        "    train,val,test = [],[],[]\n",
        "    for y, L in bylab.items():\n",
        "        random.shuffle(L)\n",
        "        n = len(L)\n",
        "        n_test = max(1, int(round(test_frac*n)))\n",
        "        n_val  = max(1, int(round(val_frac*n)))\n",
        "        test  += L[:n_test]\n",
        "        val   += L[n_test:n_test+n_val]\n",
        "        train += L[n_test+n_val:]\n",
        "    return train,val,test\n",
        "\n",
        "# --------------------------- TCN --------------------------\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, c): super().__init__(); self.c=c\n",
        "    def forward(self, x): return x[:, :, :-self.c].contiguous() if self.c>0 else x\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_in, n_out, k, dilation, padding, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv1d(n_in, n_out, k, padding=padding, dilation=dilation),\n",
        "            nn.ReLU(), nn.Dropout(dropout), Chomp1d(padding),\n",
        "            nn.Conv1d(n_out, n_out, k, padding=padding, dilation=dilation),\n",
        "            nn.ReLU(), nn.Dropout(dropout), Chomp1d(padding),\n",
        "        )\n",
        "        self.down = nn.Conv1d(n_in, n_out, 1) if n_in!=n_out else nn.Identity()\n",
        "    def forward(self, x):\n",
        "        out = self.seq(x)\n",
        "        return out + self.down(x)\n",
        "\n",
        "class TCNClassifier(nn.Module):\n",
        "    def __init__(self, feats=34, channels=(64,64,128), k=5, dropout=0.2, num_classes=10):\n",
        "        super().__init__()\n",
        "        layers=[]; n_in=feats\n",
        "        for i, ch in enumerate(channels):\n",
        "            dil = 2**i\n",
        "            pad = (k-1)*dil\n",
        "            layers.append(TemporalBlock(n_in, ch, k, dil, pad, dropout))\n",
        "            n_in = ch\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc   = nn.Linear(n_in, num_classes)\n",
        "    def forward(self, x):              # x: (B,T,F)\n",
        "        x = x.transpose(1,2)           # (B,F,T)\n",
        "        y = self.tcn(x)                # (B,C,T)\n",
        "        y = self.pool(y).squeeze(-1)   # (B,C)\n",
        "        return self.fc(y)\n",
        "\n",
        "# -------------------- Loss / sampler / eval ---------------\n",
        "def build_loss(use_class_weights, train_entries, num_classes, device, label_smoothing=0.0):\n",
        "    if use_class_weights:\n",
        "        counts = Counter([y for _,y in train_entries])\n",
        "        freq   = np.array([counts.get(i,0) for i in range(num_classes)], dtype=np.float32)\n",
        "        w = torch.tensor(1.0/np.maximum(freq,1), dtype=torch.float32, device=device)\n",
        "        w = w / w.mean()\n",
        "        return nn.CrossEntropyLoss(weight=w, label_smoothing=label_smoothing, reduction='none')\n",
        "    return nn.CrossEntropyLoss(label_smoothing=label_smoothing, reduction='none')\n",
        "\n",
        "def build_sampler(use_sampler, train_entries, num_classes):\n",
        "    if not use_sampler: return None\n",
        "    counts = Counter([y for _,y in train_entries])\n",
        "    freq   = np.array([counts.get(i,0) for i in range(num_classes)], dtype=np.float32)\n",
        "    cw = 1.0/np.maximum(freq,1); cw = cw/ cw.mean()\n",
        "    weights = np.array([cw[y] for _,y in train_entries], dtype=np.float32)\n",
        "    return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_loader(net, loader, device, criterion_reduced):\n",
        "    net.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = net(xb)\n",
        "        loss = criterion_reduced(logits, yb)\n",
        "        loss_sum += float(loss) * yb.size(0)\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "    return loss_sum/max(total,1), correct/max(total,1)\n",
        "\n",
        "def reduce_mean(loss_vec):\n",
        "    # loss_vec is (B,), already per-sample (because we set reduction='none')\n",
        "    return loss_vec.mean()\n",
        "\n",
        "# ------------------------ TTA helpers ---------------------\n",
        "def predict_with_tta(model, xb, device):\n",
        "    # xb: (B,T,34)\n",
        "    logits = model(xb.to(device))\n",
        "    x_np = xb.cpu().numpy()\n",
        "    x_flip_np = np.stack([horizontal_flip_sequence(xx) for xx in x_np], axis=0)\n",
        "    x_flip = torch.tensor(x_flip_np, dtype=xb.dtype, device=device)\n",
        "    logits_flip = model(x_flip)\n",
        "    return (logits + logits_flip) / 2\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_preds(model, loader, device, use_tta=False):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    for xb, yb in loader:\n",
        "        if use_tta:\n",
        "            logits = predict_with_tta(model, xb, device)\n",
        "        else:\n",
        "            logits = model(xb.to(device))\n",
        "        p = logits.argmax(1).cpu().numpy()\n",
        "        preds.append(p); trues.append(yb.numpy())\n",
        "    return np.concatenate(preds), np.concatenate(trues)\n",
        "\n",
        "# ---------------- Pose-correction feedback (angles) -------\n",
        "LHIP,RHIP,LKNEE,RKNEE,LANK,RANK = 11,12,13,14,15,16\n",
        "LSHO,RSHO,LELB,RELB,LWR,RWR     = 5,6,7,8,9,10\n",
        "\n",
        "def angle_deg(a, b, c):\n",
        "    ba = a - b; bc = c - b\n",
        "    den = (np.linalg.norm(ba)*np.linalg.norm(bc))\n",
        "    if den == 0: return 180.0\n",
        "    cosv = np.clip(np.dot(ba,bc)/den, -1.0, 1.0)\n",
        "    return float(np.degrees(np.arccos(cosv)))\n",
        "\n",
        "def angles_from_seq(seq_xy: np.ndarray):\n",
        "    stats = {\"knee_r\":[], \"knee_l\":[], \"elbow_r\":[], \"elbow_l\":[]}\n",
        "    for t in range(len(seq_xy)):\n",
        "        xy = seq_xy[t].reshape(17,2)\n",
        "        stats[\"knee_r\"].append(angle_deg(xy[RHIP], xy[RKNEE], xy[RANK]))\n",
        "        stats[\"knee_l\"].append(angle_deg(xy[LHIP], xy[LKNEE], xy[LANK]))\n",
        "        stats[\"elbow_r\"].append(angle_deg(xy[RSHO], xy[RELB], xy[RWR]))\n",
        "        stats[\"elbow_l\"].append(angle_deg(xy[LSHO], xy[LELB], xy[LWR]))\n",
        "    return {k: {\n",
        "        \"min\": float(np.min(v)), \"max\": float(np.max(v)),\n",
        "        \"p10\": float(np.percentile(v,10)), \"p90\": float(np.percentile(v,90))\n",
        "    } for k,v in stats.items()}\n",
        "\n",
        "def feedback_from_stats(label: str, stats: dict):\n",
        "    label_l = (label or \"\").lower()\n",
        "    fb = []\n",
        "    if any(s in label_l for s in [\"squat\",\"leg extension\",\"hip thrust\"]):\n",
        "        knee_min = min(stats[\"knee_l\"][\"min\"], stats[\"knee_r\"][\"min\"])\n",
        "        if knee_min > 100: fb.append(\"Squat depth shallow — aim for ~90° knee flexion.\")\n",
        "        elif knee_min < 60: fb.append(\"Very deep — ensure control and comfort range.\")\n",
        "        else: fb.append(\"Good squat depth.\")\n",
        "    if any(s in label_l for s in [\"deadlift\",\"romanian\"]):\n",
        "        knee_min = min(stats[\"knee_l\"][\"min\"], stats[\"knee_r\"][\"min\"])\n",
        "        if knee_min < 70: fb.append(\"Knees bending a lot — hinge more from hips.\")\n",
        "    if any(s in label_l for s in [\"push\",\"press\",\"bench\"]):\n",
        "        emax = max(stats[\"elbow_l\"][\"p90\"], stats[\"elbow_r\"][\"p90\"])\n",
        "        if emax > 130: fb.append(\"Elbows flared — consider ~45° to protect shoulders.\")\n",
        "        else: fb.append(\"Elbow tracking looks reasonable.\")\n",
        "    if \"curl\" in label_l:\n",
        "        emin = min(stats[\"elbow_l\"][\"min\"], stats[\"elbow_r\"][\"min\"])\n",
        "        if emin > 80: fb.append(\"Limited elbow flexion — curl through fuller range.\")\n",
        "    if \"plank\" in label_l:\n",
        "        fb.append(\"Keep a straight line head→heels; avoid hip sag.\")\n",
        "    if not fb:\n",
        "        fb.append(\"Form looks okay; review depth and control.\")\n",
        "    return fb\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_feedback_on_file(npy_path: Path, model, labels, device, seq_len):\n",
        "    npy_path = Path(npy_path)\n",
        "    if not npy_path.exists():\n",
        "        print(f\"[analyze_npy] File not found: {npy_path}\")\n",
        "        return\n",
        "    seq = np.load(npy_path)\n",
        "    seq = pad_or_center_trim(seq, seq_len)\n",
        "    x = torch.tensor(seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    model.eval()\n",
        "    logits = model(x)\n",
        "    pred_id = int(logits.argmax(1).item())\n",
        "    pred_label = labels[pred_id] if 0 <= pred_id < len(labels) else str(pred_id)\n",
        "    print(f\"[analyze_npy] Predicted: {pred_label} (id={pred_id})\")\n",
        "    stats = angles_from_seq(seq)\n",
        "    cues = feedback_from_stats(pred_label, stats)\n",
        "    print(\"[feedback] angle stats:\", json.dumps(stats, indent=2))\n",
        "    print(\"[feedback] suggestions:\")\n",
        "    for c in cues: print(\" -\", c)\n",
        "\n",
        "# ------------------------- MixUp / Focal ------------------\n",
        "def mixup_batch(x, y, alpha=0.4):\n",
        "    if alpha <= 0: return x, y, None\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    index = torch.randperm(x.size(0), device=x.device)\n",
        "    x_mix = lam * x + (1 - lam) * x[index]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x_mix, (y_a, y_b), lam\n",
        "\n",
        "def mixup_criterion(criterion_vec, pred, y_mix):\n",
        "    # criterion_vec returns (B,) per-sample; we need mean after weighting\n",
        "    y_a, y_b, lam = y_mix\n",
        "    loss_a = criterion_vec(pred, y_a)\n",
        "    loss_b = criterion_vec(pred, y_b)\n",
        "    return (lam * loss_a + (1 - lam) * loss_b).mean()\n",
        "\n",
        "class FocalWrapper(nn.Module):\n",
        "    \"\"\"Wraps a per-sample CE (reduction='none') with focal modulation.\"\"\"\n",
        "    def __init__(self, base_ce, gamma=1.5):\n",
        "        super().__init__(); self.ce=base_ce; self.gamma=gamma\n",
        "    def forward(self, logits, target):\n",
        "        ce = self.ce(logits, target)                      # (B,)\n",
        "        with torch.no_grad():\n",
        "            pt = torch.softmax(logits, dim=1).gather(1, target.unsqueeze(1)).clamp_min(1e-8).squeeze(1)\n",
        "        mod = (1 - pt) ** self.gamma                      # (B,)\n",
        "        return (mod * ce)                                 # keep per-sample; caller should mean()\n",
        "\n",
        "# --------------------------- Report -----------------------\n",
        "def do_report(model, val_dl, test_dl, labels, device, out_dir=None, use_tta=False):\n",
        "    try:\n",
        "        from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "    except Exception:\n",
        "        import subprocess, sys\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"scikit-learn\"])\n",
        "        from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "    pv, yv = collect_preds(model, val_dl, device, use_tta)\n",
        "    pt, yt = collect_preds(model, test_dl, device, use_tta)\n",
        "\n",
        "    print(\"\\n=== Validation Report ===\")\n",
        "    print(classification_report(yv, pv, target_names=labels, digits=3))\n",
        "    print(confusion_matrix(yv, pv))\n",
        "\n",
        "    print(\"\\n=== Test Report ===\")\n",
        "    print(classification_report(yt, pt, target_names=labels, digits=3))\n",
        "    cm = confusion_matrix(yt, pt)\n",
        "    print(cm)\n",
        "\n",
        "    if out_dir:\n",
        "        out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        import pandas as pd\n",
        "        p,r,f,s = precision_recall_fscore_support(yt, pt, labels=list(range(len(labels))), zero_division=0)\n",
        "        pd.DataFrame({\"label\":labels,\"precision\":p,\"recall\":r,\"f1\":f,\"support\":s}).to_csv(out_dir/\"test_report.csv\", index=False)\n",
        "        pd.DataFrame(cm, index=labels, columns=labels).to_csv(out_dir/\"test_confusion_matrix.csv\", index=True)\n",
        "        print(f\"📁 Reports saved to: {out_dir}\")\n",
        "\n",
        "# ---------------------------- Main ------------------------\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(\"Train TCN on cached pose sequences (+TTA, focal, hparam-aware ckpt)\")\n",
        "    ap.add_argument(\"--cache_dir\", type=Path, required=True)\n",
        "    ap.add_argument(\"--seq_len\", type=int, default=60)\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=8)\n",
        "    ap.add_argument(\"--epochs\", type=int, default=25)\n",
        "    ap.add_argument(\"--lr\", type=float, default=3e-4)\n",
        "    ap.add_argument(\"--weight_decay\", type=float, default=1e-4)\n",
        "    ap.add_argument(\"--channels\", type=str, default=\"64,64,128\")\n",
        "    ap.add_argument(\"--kernel\", type=int, default=5)\n",
        "    ap.add_argument(\"--dropout\", type=float, default=0.2)\n",
        "    ap.add_argument(\"--use_aug\", action=\"store_true\")\n",
        "    ap.add_argument(\"--use_class_weights\", action=\"store_true\")\n",
        "    ap.add_argument(\"--use_sampler\", action=\"store_true\")\n",
        "    ap.add_argument(\"--label_smoothing\", type=float, default=0.0)\n",
        "    ap.add_argument(\"--scheduler\", type=str, default=\"cosine\", choices=[\"none\",\"cosine\"])\n",
        "    ap.add_argument(\"--patience\", type=int, default=6)\n",
        "    ap.add_argument(\"--save_path\", type=Path, default=Path(\"./best_tcn.pt\"))\n",
        "    ap.add_argument(\"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    ap.add_argument(\"--seed\", type=int, default=42)\n",
        "    ap.add_argument(\"--eval_only\", action=\"store_true\")\n",
        "    ap.add_argument(\"--checkpoint\", type=Path, default=None)\n",
        "    ap.add_argument(\"--analyze_npy\", type=Path, default=None)\n",
        "\n",
        "    # NEW:\n",
        "    ap.add_argument(\"--report\", action=\"store_true\")\n",
        "    ap.add_argument(\"--report_path\", type=Path, default=None)\n",
        "    ap.add_argument(\"--tta\", action=\"store_true\", help=\"horizontal flip TTA at eval/report\")\n",
        "    ap.add_argument(\"--mixup\", action=\"store_true\")\n",
        "    ap.add_argument(\"--mixup_alpha\", type=float, default=0.4)\n",
        "    ap.add_argument(\"--time_mask_prob\", type=float, default=0.0)\n",
        "    ap.add_argument(\"--time_mask_max\", type=int, default=0)\n",
        "    ap.add_argument(\"--focal\", action=\"store_true\")\n",
        "    ap.add_argument(\"--focal_gamma\", type=float, default=1.5)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    set_seed(args.seed)\n",
        "\n",
        "    # Data\n",
        "    index, labels, label2id = discover_cache(args.cache_dir)\n",
        "    num_classes = len(labels)\n",
        "    if len(index) == 0:\n",
        "        raise SystemExit(f\"No sequences found in {args.cache_dir}\")\n",
        "\n",
        "    train, val, test = stratified_split(index, val_frac=0.15, test_frac=0.15, seed=args.seed)\n",
        "\n",
        "    pin = torch.cuda.is_available()\n",
        "    sampler = build_sampler(args.use_sampler, train, num_classes)\n",
        "    train_ds = PoseSeqDS(train, args.seq_len, True, args.use_aug, args.time_mask_prob, args.time_mask_max)\n",
        "    val_ds   = PoseSeqDS(val,   args.seq_len, False, False, 0.0, 0)\n",
        "    test_ds  = PoseSeqDS(test,  args.seq_len, False, False, 0.0, 0)\n",
        "\n",
        "    train_dl = DataLoader(train_ds, batch_size=args.batch_size,\n",
        "                          shuffle=(sampler is None), sampler=sampler,\n",
        "                          num_workers=2, pin_memory=pin)\n",
        "    val_dl   = DataLoader(val_ds,   batch_size=args.batch_size, shuffle=False, num_workers=2, pin_memory=pin)\n",
        "    test_dl  = DataLoader(test_ds,  batch_size=args.batch_size, shuffle=False, num_workers=2, pin_memory=pin)\n",
        "\n",
        "    # Model & training utils\n",
        "    channels = tuple(int(x) for x in args.channels.split(\",\") if x.strip())\n",
        "    model = TCNClassifier(feats=34, channels=channels, k=args.kernel, dropout=args.dropout,\n",
        "                          num_classes=num_classes).to(args.device)\n",
        "\n",
        "    # Per-sample CE (reduction='none'); we mean it manually to support Focal/MixUp\n",
        "    base_ce = build_loss(args.use_class_weights, train, num_classes, args.device, args.label_smoothing)\n",
        "    criterion_vec = FocalWrapper(base_ce, gamma=args.focal_gamma) if args.focal else base_ce\n",
        "    criterion_reduced = lambda pred, target: reduce_mean(criterion_vec(pred, target))\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs) if args.scheduler==\"cosine\" else None\n",
        "\n",
        "    # --------- Load checkpoint (hparam-aware) ----------\n",
        "    if args.checkpoint and Path(args.checkpoint).exists():\n",
        "        ckpt_obj = torch.load(args.checkpoint, map_location=args.device)\n",
        "        if isinstance(ckpt_obj, dict) and \"state_dict\" in ckpt_obj:\n",
        "            hp = ckpt_obj.get(\"hparams\", {})\n",
        "            ch_from_ckpt = tuple(hp.get(\"channels\", channels))\n",
        "            k_from_ckpt  = int(hp.get(\"kernel\", args.kernel))\n",
        "            if ch_from_ckpt != channels or k_from_ckpt != args.kernel:\n",
        "                print(f\"[info] Overriding model hparams from checkpoint: channels={ch_from_ckpt}, kernel={k_from_ckpt}\")\n",
        "                channels = ch_from_ckpt\n",
        "                args.kernel = k_from_ckpt\n",
        "                model = TCNClassifier(feats=34, channels=channels, k=args.kernel,\n",
        "                                      dropout=args.dropout, num_classes=num_classes).to(args.device)\n",
        "            model.load_state_dict(ckpt_obj[\"state_dict\"], strict=True)\n",
        "            if \"labels\" in ckpt_obj and ckpt_obj[\"labels\"]:\n",
        "                labels = ckpt_obj[\"labels\"]; num_classes = len(labels)\n",
        "            print(f\"Loaded checkpoint: {args.checkpoint}\")\n",
        "        else:\n",
        "            model.load_state_dict(ckpt_obj, strict=True)\n",
        "            print(f\"Loaded raw state_dict: {args.checkpoint}\")\n",
        "\n",
        "    # --------- Eval-only? ----------\n",
        "    if args.eval_only:\n",
        "        vl, va = eval_loader(model, val_dl, args.device, criterion_reduced)\n",
        "        tl, ta = eval_loader(model, test_dl, args.device, criterion_reduced)\n",
        "        print(f\"[EvalOnly] val_loss={vl:.4f} val_acc={va:.3f} | test_loss={tl:.4f} test_acc={ta:.3f}\")\n",
        "        if args.report:\n",
        "            do_report(model, val_dl, test_dl, labels, args.device, out_dir=args.report_path, use_tta=args.tta)\n",
        "        if args.analyze_npy:\n",
        "            run_feedback_on_file(args.analyze_npy, model, labels, args.device, args.seq_len)\n",
        "        return\n",
        "\n",
        "    # ----------------- Train -----------------\n",
        "    best_val, bad = float(\"inf\"), 0\n",
        "    for ep in range(1, args.epochs+1):\n",
        "        model.train(); running=0.0; batches=0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(args.device), yb.to(args.device)\n",
        "            if args.mixup:\n",
        "                x_mix, y_mix, lam = mixup_batch(xb, yb, alpha=args.mixup_alpha)\n",
        "                logits = model(x_mix)\n",
        "                loss = mixup_criterion(criterion_vec, logits, (y_mix[0], y_mix[1], lam))\n",
        "            else:\n",
        "                logits = model(xb)\n",
        "                loss = reduce_mean(criterion_vec(logits, yb))\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "            running += float(loss); batches += 1\n",
        "\n",
        "        tr = running/max(batches,1)\n",
        "        vl, va = eval_loader(model, val_dl, args.device, criterion_reduced)\n",
        "        if scheduler: scheduler.step()\n",
        "        print(f\"Epoch {ep:02d} | train={tr:.4f} | val_loss={vl:.4f} | val_acc={va:.3f}\")\n",
        "\n",
        "        if vl < best_val:\n",
        "            best_val, bad = vl, 0\n",
        "            ckpt = {\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"hparams\": {\n",
        "                    \"feats\": 34,\n",
        "                    \"channels\": channels,\n",
        "                    \"kernel\": args.kernel,\n",
        "                    \"dropout\": args.dropout,\n",
        "                    \"num_classes\": num_classes,\n",
        "                    \"seq_len\": args.seq_len\n",
        "                },\n",
        "                \"labels\": labels\n",
        "            }\n",
        "            torch.save(ckpt, args.save_path)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= args.patience:\n",
        "                print(\"⏹️ Early stopping.\"); break\n",
        "\n",
        "    # ----------------- Test best -----------------\n",
        "    ckpt_obj = torch.load(args.save_path, map_location=args.device)\n",
        "    if isinstance(ckpt_obj, dict) and \"state_dict\" in ckpt_obj:\n",
        "        hp = ckpt_obj.get(\"hparams\", {})\n",
        "        ch_from_ckpt = tuple(hp.get(\"channels\", channels))\n",
        "        k_from_ckpt  = int(hp.get(\"kernel\", args.kernel))\n",
        "        if ch_from_ckpt != channels or k_from_ckpt != args.kernel:\n",
        "            print(f\"[info] Using saved hparams for best model: channels={ch_from_ckpt}, kernel={k_from_ckpt}\")\n",
        "            channels = ch_from_ckpt\n",
        "            args.kernel = k_from_ckpt\n",
        "            model = TCNClassifier(feats=34, channels=channels, k=args.kernel,\n",
        "                                  dropout=args.dropout, num_classes=num_classes).to(args.device)\n",
        "        model.load_state_dict(ckpt_obj[\"state_dict\"], strict=True)\n",
        "        if \"labels\" in ckpt_obj and ckpt_obj[\"labels\"]:\n",
        "            labels = ckpt_obj[\"labels\"]; num_classes = len(labels)\n",
        "    else:\n",
        "        model.load_state_dict(ckpt_obj, strict=True)\n",
        "\n",
        "    tl, ta = eval_loader(model, test_dl, args.device, criterion_reduced)\n",
        "    print(f\"🏁 Test(best): loss={tl:.4f} | acc={ta:.3f}\")\n",
        "\n",
        "    if args.report:\n",
        "        do_report(model, val_dl, test_dl, labels, args.device, out_dir=args.report_path, use_tta=args.tta)\n",
        "\n",
        "    if args.analyze_npy:\n",
        "        run_feedback_on_file(args.analyze_npy, model, labels, args.device, args.seq_len)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFlSJjbxs-Gm",
        "outputId": "45ccff18-8688-4ffd-9ed2-42a670300209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_tcn.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_tcn.py --cache_dir /content/pose_seq_yolo \\\n",
        "  --epochs 35 --batch_size 8 \\\n",
        "  --use_aug --use_class_weights --use_sampler \\\n",
        "  --mixup --mixup_alpha 0.3 \\\n",
        "  --time_mask_prob 0.10 --time_mask_max 12 \\\n",
        "  --label_smoothing 0.05 --focal --focal_gamma 1.5 \\\n",
        "  --scheduler cosine --patience 10 \\\n",
        "  --seq_len 90 --channels 64,128,256 --kernel 7 \\\n",
        "  --report --tta --report_path /content/tcn_reports_v3 \\\n",
        "  --save_path /content/best_tcn.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeAxs1o14fzo",
        "outputId": "f01b8d82-c7db-46d6-ab3b-e4fe2656f888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/train_tcn.py:471: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
            "  running += float(loss); batches += 1\n",
            "Epoch 01 | train=2.4562 | val_loss=1.9691 | val_acc=0.105\n",
            "Epoch 02 | train=1.8370 | val_loss=1.5205 | val_acc=0.253\n",
            "Epoch 03 | train=1.7210 | val_loss=1.4516 | val_acc=0.179\n",
            "Epoch 04 | train=1.4384 | val_loss=1.3334 | val_acc=0.232\n",
            "Epoch 05 | train=1.4185 | val_loss=1.3118 | val_acc=0.158\n",
            "Epoch 06 | train=1.2706 | val_loss=1.1804 | val_acc=0.284\n",
            "Epoch 07 | train=1.2926 | val_loss=1.1497 | val_acc=0.295\n",
            "Epoch 08 | train=1.1188 | val_loss=1.1371 | val_acc=0.337\n",
            "Epoch 09 | train=1.1350 | val_loss=1.0501 | val_acc=0.305\n",
            "Epoch 10 | train=1.1366 | val_loss=0.9246 | val_acc=0.389\n",
            "Epoch 11 | train=1.1517 | val_loss=1.0527 | val_acc=0.379\n",
            "Epoch 12 | train=1.0911 | val_loss=0.8916 | val_acc=0.411\n",
            "Epoch 13 | train=1.0772 | val_loss=0.9540 | val_acc=0.411\n",
            "Epoch 14 | train=1.0390 | val_loss=0.8950 | val_acc=0.484\n",
            "Epoch 15 | train=0.9851 | val_loss=0.9046 | val_acc=0.379\n",
            "Epoch 16 | train=1.0517 | val_loss=0.9230 | val_acc=0.442\n",
            "Epoch 17 | train=1.0516 | val_loss=0.9061 | val_acc=0.463\n",
            "Epoch 18 | train=0.9449 | val_loss=0.8355 | val_acc=0.484\n",
            "Epoch 19 | train=0.8442 | val_loss=0.7739 | val_acc=0.600\n",
            "Epoch 20 | train=0.7656 | val_loss=0.7218 | val_acc=0.547\n",
            "Epoch 21 | train=0.9072 | val_loss=0.7960 | val_acc=0.600\n",
            "Epoch 22 | train=0.8119 | val_loss=0.7462 | val_acc=0.674\n",
            "Epoch 23 | train=0.8132 | val_loss=0.7314 | val_acc=0.558\n",
            "Epoch 24 | train=0.7169 | val_loss=0.6963 | val_acc=0.632\n",
            "Epoch 25 | train=0.8043 | val_loss=0.7307 | val_acc=0.611\n",
            "Epoch 26 | train=0.8303 | val_loss=0.7020 | val_acc=0.642\n",
            "Epoch 27 | train=0.9436 | val_loss=0.7127 | val_acc=0.632\n",
            "Epoch 28 | train=0.8056 | val_loss=0.7191 | val_acc=0.600\n",
            "Epoch 29 | train=0.7970 | val_loss=0.7166 | val_acc=0.589\n",
            "Epoch 30 | train=0.7711 | val_loss=0.6883 | val_acc=0.600\n",
            "Epoch 31 | train=0.7467 | val_loss=0.6875 | val_acc=0.600\n",
            "Epoch 32 | train=0.7706 | val_loss=0.6887 | val_acc=0.600\n",
            "Epoch 33 | train=0.7543 | val_loss=0.6857 | val_acc=0.611\n",
            "Epoch 34 | train=0.8319 | val_loss=0.6843 | val_acc=0.621\n",
            "Epoch 35 | train=0.8074 | val_loss=0.6838 | val_acc=0.621\n",
            "🏁 Test(best): loss=0.6326 | acc=0.621\n",
            "\n",
            "=== Validation Report ===\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl      0.667     0.222     0.333         9\n",
            "        bench press      0.750     0.429     0.545         7\n",
            "  chest fly machine      0.600     0.750     0.667         4\n",
            "           deadlift      0.600     0.600     0.600         5\n",
            "decline bench press      0.500     0.500     0.500         2\n",
            "        hammer curl      0.375     1.000     0.545         3\n",
            "         hip thrust      0.750     1.000     0.857         3\n",
            "incline bench press      0.429     0.750     0.545         4\n",
            "       lat pulldown      1.000     0.500     0.667         8\n",
            "      lateral raise      0.833     0.833     0.833         6\n",
            "      leg extension      1.000     0.500     0.667         4\n",
            "         leg raises      0.429     1.000     0.600         3\n",
            "              plank      0.250     1.000     0.400         1\n",
            "            pull Up      0.333     0.500     0.400         4\n",
            "            push-up      1.000     0.500     0.667         8\n",
            "  romanian deadlift      0.500     1.000     0.667         2\n",
            "      russian twist      1.000     1.000     1.000         2\n",
            "     shoulder press      0.667     0.667     0.667         3\n",
            "              squat      0.500     0.250     0.333         4\n",
            "          t bar row      0.750     1.000     0.857         3\n",
            "    tricep Pushdown      0.625     0.714     0.667         7\n",
            "        tricep dips      1.000     0.333     0.500         3\n",
            "\n",
            "           accuracy                          0.611        95\n",
            "          macro avg      0.662     0.684     0.614        95\n",
            "       weighted avg      0.708     0.611     0.604        95\n",
            "\n",
            "[[2 0 1 0 0 5 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0 1 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 4 0 0 1 0 2 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 3 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 5 0]\n",
            " [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
            "\n",
            "=== Test Report ===\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "barbell biceps curl      0.857     0.667     0.750         9\n",
            "        bench press      1.000     0.286     0.444         7\n",
            "  chest fly machine      0.750     0.750     0.750         4\n",
            "           deadlift      1.000     0.400     0.571         5\n",
            "decline bench press      0.000     0.000     0.000         2\n",
            "        hammer curl      0.250     0.667     0.364         3\n",
            "         hip thrust      0.000     0.000     0.000         3\n",
            "incline bench press      0.571     1.000     0.727         4\n",
            "       lat pulldown      1.000     0.500     0.667         8\n",
            "      lateral raise      1.000     0.833     0.909         6\n",
            "      leg extension      0.800     1.000     0.889         4\n",
            "         leg raises      0.500     0.667     0.571         3\n",
            "              plank      0.167     1.000     0.286         1\n",
            "            pull Up      0.400     0.500     0.444         4\n",
            "            push-up      1.000     0.750     0.857         8\n",
            "  romanian deadlift      0.286     1.000     0.444         2\n",
            "      russian twist      0.400     1.000     0.571         2\n",
            "     shoulder press      0.600     1.000     0.750         3\n",
            "              squat      1.000     0.500     0.667         4\n",
            "          t bar row      0.500     0.333     0.400         3\n",
            "    tricep Pushdown      0.750     0.429     0.545         7\n",
            "        tricep dips      1.000     1.000     1.000         3\n",
            "\n",
            "           accuracy                          0.621        95\n",
            "          macro avg      0.629     0.649     0.573        95\n",
            "       weighted avg      0.749     0.621     0.628        95\n",
            "\n",
            "[[6 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 2 0 0 1 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 4 0 0 1 0 2 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0 6 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            " [0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 3 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]]\n",
            "📁 Reports saved to: /content/tcn_reports_v3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile infer_baseline.py\n",
        "#!/usr/bin/env python3\n",
        "# infer_baseline.py\n",
        "import argparse, json, re\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ------------------- TCN (baseline) -------------------\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, c): super().__init__(); self.c=c\n",
        "    def forward(self, x): return x[:, :, :-self.c].contiguous() if self.c>0 else x\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_in, n_out, k, dilation, padding, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv1d(n_in, n_out, k, padding=padding, dilation=dilation),\n",
        "            nn.ReLU(), nn.Dropout(dropout), Chomp1d(padding),\n",
        "            nn.Conv1d(n_out, n_out, k, padding=padding, dilation=dilation),\n",
        "            nn.ReLU(), nn.Dropout(dropout), Chomp1d(padding),\n",
        "        )\n",
        "        self.down = nn.Conv1d(n_in, n_out, 1) if n_in!=n_out else nn.Identity()\n",
        "    def forward(self, x):\n",
        "        out = self.seq(x)\n",
        "        return out + self.down(x)\n",
        "\n",
        "class TCNClassifier(nn.Module):\n",
        "    def __init__(self, feats=34, channels=(64,128,256), k=7, dropout=0.0, num_classes=10):\n",
        "        super().__init__()\n",
        "        layers=[]; n_in=feats\n",
        "        for i, ch in enumerate(channels):\n",
        "            dil = 2**i\n",
        "            pad = (k-1)*dil\n",
        "            layers.append(TemporalBlock(n_in, ch, k, dil, pad, dropout))\n",
        "            n_in = ch\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc   = nn.Linear(n_in, num_classes)\n",
        "    def forward(self, x):                # x: (B,T,F)\n",
        "        x = x.transpose(1,2)             # (B,F,T)\n",
        "        y = self.tcn(x)                  # (B,C,T)\n",
        "        y = self.pool(y).squeeze(-1)     # (B,C)\n",
        "        return self.fc(y)\n",
        "\n",
        "# ------------------- Seq utilities --------------------\n",
        "def pad_or_center_trim(x: np.ndarray, T: int) -> np.ndarray:\n",
        "    t = len(x)\n",
        "    if t == T: return x\n",
        "    if t > T:\n",
        "        s = (t - T)//2\n",
        "        return x[s:s+T]\n",
        "    pad = np.zeros((T - t, x.shape[1]), dtype=x.dtype)\n",
        "    return np.concatenate([x, pad], axis=0)\n",
        "\n",
        "# ---------- Optional: video → YOLOv8 pose seq ----------\n",
        "def extract_pose_sequence_yolo_batched(\n",
        "    video_path: Path, every_n=3, batch_size=32, imgsz=448, conf=0.25, device=\"cpu\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Optional. Requires: pip install ultralytics opencv-python-headless\n",
        "    Produces normalized 17x2 sequences → (T,34)\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "    LEFT_HIP, RIGHT_HIP = 11, 12\n",
        "    LEFT_SHO, RIGHT_SHO = 5, 6\n",
        "\n",
        "    def _pre(frame, target=448):\n",
        "        h, w = frame.shape[:2]\n",
        "        if max(h, w) > target:\n",
        "            s = target / max(h, w)\n",
        "            frame = cv2.resize(frame, (int(w*s), int(h*s)), interpolation=cv2.INTER_AREA)\n",
        "        return frame\n",
        "\n",
        "    pose_model = YOLO(\"yolov8n-pose.pt\")\n",
        "    if torch.cuda.is_available() and device != \"cpu\":\n",
        "        pose_model.to(0)\n",
        "        try: pose_model.model.half()\n",
        "        except: pass\n",
        "\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    frames=[]; fidx=0\n",
        "    while cap.isOpened():\n",
        "        ok, frame = cap.read()\n",
        "        if not ok: break\n",
        "        if fidx % every_n == 0:\n",
        "            frames.append(_pre(frame, imgsz))\n",
        "        fidx += 1\n",
        "    cap.release()\n",
        "\n",
        "    if not frames:\n",
        "        return np.zeros((0,34), dtype=np.float32)\n",
        "\n",
        "    seq=[]\n",
        "    for i in range(0, len(frames), batch_size):\n",
        "        batch = frames[i:i+batch_size]\n",
        "        results = pose_model.predict(\n",
        "            batch, imgsz=imgsz, device=0 if (torch.cuda.is_available() and device!=\"cpu\") else device,\n",
        "            conf=conf, max_det=1, verbose=False\n",
        "        )\n",
        "        for r in results:\n",
        "            if not hasattr(r,\"keypoints\") or r.keypoints is None or len(r.keypoints)==0:\n",
        "                continue\n",
        "            xy = r.keypoints.xy[0].float().cpu().numpy()  # (17,2)\n",
        "            origin = (xy[LEFT_HIP] + xy[RIGHT_HIP]) / 2.0\n",
        "            shoulder_mid = (xy[LEFT_SHO] + xy[RIGHT_SHO]) / 2.0\n",
        "            scale = np.linalg.norm(shoulder_mid - origin) or 1.0\n",
        "            xy_norm = (xy - origin) / scale\n",
        "            seq.append(xy_norm.reshape(-1))\n",
        "    if not seq:\n",
        "        return np.zeros((0,34), dtype=np.float32)\n",
        "    return np.asarray(seq, dtype=np.float32)\n",
        "\n",
        "# ----------------- Angles + feedback -------------------\n",
        "LHIP,RHIP,LKNEE,RKNEE,LANK,RANK = 11,12,13,14,15,16\n",
        "LSHO,RSHO,LELB,RELB,LWR,RWR     = 5,6,7,8,9,10\n",
        "\n",
        "def angle_deg(a, b, c):\n",
        "    ba = a - b; bc = c - b\n",
        "    den = (np.linalg.norm(ba)*np.linalg.norm(bc))\n",
        "    if den == 0: return 180.0\n",
        "    cosv = np.clip(np.dot(ba,bc)/den, -1.0, 1.0)\n",
        "    return float(np.degrees(np.arccos(cosv)))\n",
        "\n",
        "def angles_from_seq(seq_xy: np.ndarray):\n",
        "    stats = {\"knee_r\":[], \"knee_l\":[], \"elbow_r\":[], \"elbow_l\":[]}\n",
        "    for t in range(len(seq_xy)):\n",
        "        xy = seq_xy[t].reshape(17,2)\n",
        "        stats[\"knee_r\"].append(angle_deg(xy[RHIP], xy[RKNEE], xy[RANK]))\n",
        "        stats[\"knee_l\"].append(angle_deg(xy[LHIP], xy[LKNEE], xy[LANK]))\n",
        "        stats[\"elbow_r\"].append(angle_deg(xy[RSHO], xy[RELB], xy[RWR]))\n",
        "        stats[\"elbow_l\"].append(angle_deg(xy[LSHO], xy[LELB], xy[LWR]))\n",
        "    return {k: {\n",
        "        \"min\": float(np.min(v)), \"max\": float(np.max(v)),\n",
        "        \"p10\": float(np.percentile(v,10)), \"p90\": float(np.percentile(v,90))\n",
        "    } for k,v in stats.items()}\n",
        "\n",
        "def feedback_from_stats(label: str, stats: dict):\n",
        "    L = (label or \"\").lower()\n",
        "    fb=[]\n",
        "    # Squat / hinge-ish cues\n",
        "    if any(s in L for s in [\"squat\",\"leg extension\",\"hip thrust\"]):\n",
        "        knee_min = min(stats[\"knee_l\"][\"min\"], stats[\"knee_r\"][\"min\"])\n",
        "        if knee_min > 100: fb.append(\"Depth shallow — aim near ~90° knee flexion.\")\n",
        "        elif knee_min < 60: fb.append(\"Very deep — ensure control and comfort.\")\n",
        "        else: fb.append(\"Good depth.\")\n",
        "    if any(s in L for s in [\"deadlift\",\"romanian\"]):\n",
        "        knee_min = min(stats[\"knee_l\"][\"min\"], stats[\"knee_r\"][\"min\"])\n",
        "        if knee_min < 70: fb.append(\"Knees bending a lot — hinge more from hips.\")\n",
        "    # Push/press elbow flare\n",
        "    if any(s in L for s in [\"push\",\"press\",\"bench\"]):\n",
        "        emax = max(stats[\"elbow_l\"][\"p90\"], stats[\"elbow_r\"][\"p90\"])\n",
        "        if emax > 130: fb.append(\"Elbows flaring — target ~45° to protect shoulders.\")\n",
        "        else: fb.append(\"Elbow tracking looks reasonable.\")\n",
        "    # Curl ROM\n",
        "    if \"curl\" in L:\n",
        "        emin = min(stats[\"elbow_l\"][\"min\"], stats[\"elbow_r\"][\"min\"])\n",
        "        if emin > 80: fb.append(\"Limited elbow flexion — curl through fuller ROM.\")\n",
        "    if \"plank\" in L:\n",
        "        fb.append(\"Keep straight line head→heels; avoid hip sag.\")\n",
        "    if not fb:\n",
        "        fb.append(\"Form looks okay; review depth and control.\")\n",
        "    return fb\n",
        "\n",
        "# -------------- Sliding-window (no TTA) ----------------\n",
        "@torch.no_grad()\n",
        "def logits_on_seq(model, seq, device):\n",
        "    x = torch.tensor(seq, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    return model(x).squeeze(0).cpu().numpy()\n",
        "\n",
        "def vote_over_windows(model, seq_full, device, seq_len=90, hop=30):\n",
        "    T = len(seq_full)\n",
        "    if T <= seq_len:\n",
        "        return logits_on_seq(model, pad_or_center_trim(seq_full, seq_len), device)\n",
        "    logits_sum = None; count=0\n",
        "    for start in range(0, max(1, T - seq_len + 1), hop):\n",
        "        chunk = seq_full[start:start+seq_len]\n",
        "        if len(chunk) < seq_len:\n",
        "            chunk = pad_or_center_trim(chunk, seq_len)\n",
        "        L = logits_on_seq(model, chunk, device)\n",
        "        logits_sum = L if logits_sum is None else (logits_sum + L)\n",
        "        count += 1\n",
        "    return logits_sum / max(count,1)\n",
        "\n",
        "# ---------------------- Labels helper -------------------\n",
        "def load_labels(cache_dir: Path, fallback_n=None):\n",
        "    labels_json = Path(cache_dir)/\"labels.json\"\n",
        "    if labels_json.exists():\n",
        "        meta = json.loads(Path(labels_json).read_text())\n",
        "        labs = meta.get(\"labels\", [])\n",
        "        if labs: return labs\n",
        "    # fallback generate\n",
        "    if fallback_n is not None:\n",
        "        return [f\"class_{i:02d}\" for i in range(fallback_n)]\n",
        "    # infer from file prefixes if present\n",
        "    ids=[]\n",
        "    for f in Path(cache_dir).glob(\"*.npy\"):\n",
        "        m = re.match(r\"^(\\d+?)__.+?\\.npy$\", f.name)\n",
        "        if m: ids.append(int(m.group(1)))\n",
        "    return [f\"class_{i:02d}\" for i in range(max(ids)+1)] if ids else []\n",
        "\n",
        "# --------------------------- Main -----------------------\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(\"Baseline TCN inference + feedback (no TTA, no focal)\")\n",
        "    ap.add_argument(\"--checkpoint\", type=Path, required=True, help=\"baseline TCN .pt or raw state_dict\")\n",
        "    ap.add_argument(\"--cache_dir\", type=Path, required=True, help=\"dir with labels.json from training\")\n",
        "    ap.add_argument(\"--npy\", type=Path, default=None, help=\"pre-extracted pose sequence (.npy)\")\n",
        "    ap.add_argument(\"--video\", type=Path, default=None, help=\"optional video path (requires ultralytics+opencv)\")\n",
        "    ap.add_argument(\"--seq_len\", type=int, default=90)\n",
        "    ap.add_argument(\"--hop\", type=int, default=30)\n",
        "    ap.add_argument(\"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # YOLO flags (only if using --video)\n",
        "    ap.add_argument(\"--every_n\", type=int, default=3)\n",
        "    ap.add_argument(\"--imgsz\", type=int, default=448)\n",
        "    ap.add_argument(\"--conf\", type=float, default=0.25)\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    print(\"[infer] args:\", vars(args))  # sanity log\n",
        "\n",
        "    # Load model\n",
        "    obj = torch.load(args.checkpoint, map_location=args.device)\n",
        "    if isinstance(obj, dict) and \"state_dict\" in obj and \"hparams\" in obj:\n",
        "        hp = obj[\"hparams\"]\n",
        "        channels = tuple(hp.get(\"channels\", (64,128,256)))\n",
        "        kernel   = int(hp.get(\"kernel\", 7))\n",
        "        num_classes = int(hp.get(\"num_classes\", 22))\n",
        "        labels = obj.get(\"labels\") or load_labels(args.cache_dir, fallback_n=num_classes)\n",
        "        model = TCNClassifier(feats=34, channels=channels, k=kernel, dropout=0.0, num_classes=len(labels)).to(args.device)\n",
        "        model.load_state_dict(obj[\"state_dict\"], strict=True)\n",
        "    else:\n",
        "        # raw state_dict: use baseline defaults (adjust if your training used different ones)\n",
        "        labels = load_labels(args.cache_dir)\n",
        "        model = TCNClassifier(feats=34, channels=(64,128,256), k=7, dropout=0.0, num_classes=len(labels)).to(args.device)\n",
        "        model.load_state_dict(obj, strict=False)\n",
        "        print(\"[warn] Loaded raw state_dict with default channels=(64,128,256), kernel=7; ensure these match training.\")\n",
        "    model.eval()\n",
        "\n",
        "    # Get sequence\n",
        "    if args.npy:\n",
        "        if not args.npy.exists():\n",
        "            raise SystemExit(f\"npy not found: {args.npy}\")\n",
        "        seq_full = np.load(args.npy)\n",
        "    elif args.video:\n",
        "        if not args.video.exists():\n",
        "            raise SystemExit(f\"video not found: {args.video}\")\n",
        "        print(\"[info] extracting pose from video (YOLOv8n-pose)...\")\n",
        "        seq_full = extract_pose_sequence_yolo_batched(\n",
        "            args.video, every_n=args.every_n, batch_size=args.batch_size,\n",
        "            imgsz=args.imgsz, conf=args.conf, device=args.device\n",
        "        )\n",
        "    else:\n",
        "        raise SystemExit(\"Provide either --npy (recommended) or --video.\")\n",
        "\n",
        "    if len(seq_full)==0:\n",
        "        raise SystemExit(\"Empty sequence. Check video visibility/pose extraction or npy path.\")\n",
        "\n",
        "    # Predict (sliding-window vote; no TTA)\n",
        "    logits = vote_over_windows(model, seq_full, args.device, seq_len=args.seq_len, hop=args.hop)\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
        "    pred_id = int(np.argmax(probs))\n",
        "    pred_label = labels[pred_id] if 0 <= pred_id < len(labels) else str(pred_id)\n",
        "\n",
        "    print(\"\\n=== Inference (baseline TCN) ===\")\n",
        "    print(f\"Predicted class: {pred_label} (id={pred_id})\")\n",
        "    topk = min(5, len(labels))\n",
        "    order = np.argsort(-probs)[:topk]\n",
        "    for i in order:\n",
        "        print(f\"  {labels[i]:22s} p={probs[i]:.3f}\")\n",
        "\n",
        "    # Feedback (angles on center-trimmed window)\n",
        "    seq = pad_or_center_trim(seq_full, args.seq_len)\n",
        "    stats = angles_from_seq(seq)\n",
        "    cues = feedback_from_stats(pred_label, stats)\n",
        "    print(\"\\n=== Angle stats ===\")\n",
        "    print(json.dumps(stats, indent=2))\n",
        "    print(\"\\n=== Feedback ===\")\n",
        "    for c in cues: print(\" -\", c)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqVjtIXF-tSq",
        "outputId": "a0bcebb7-7e48-4770-9bf6-87d1ce3381ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting infer_baseline.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u infer_baseline.py \\\n",
        "  --checkpoint /content/best_tcn.pt \\\n",
        "  --cache_dir /content/pose_seq_yolo \\\n",
        "  --npy \"/content/pose_seq_yolo/00__barbell biceps curl_11.npy\" \\\n",
        "  --seq_len 90 --hop 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVDKTPk64icK",
        "outputId": "88fe3f87-7597-4b6c-f97e-ebb0b1ea2803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] args: {'checkpoint': PosixPath('/content/best_tcn.pt'), 'cache_dir': PosixPath('/content/pose_seq_yolo'), 'npy': PosixPath('/content/pose_seq_yolo/00__barbell biceps curl_11.npy'), 'video': None, 'seq_len': 90, 'hop': 30, 'device': 'cpu', 'every_n': 3, 'imgsz': 448, 'conf': 0.25, 'batch_size': 32}\n",
            "\n",
            "=== Inference (baseline TCN) ===\n",
            "Predicted class: squat (id=18)\n",
            "  squat                  p=0.174\n",
            "  hammer curl            p=0.136\n",
            "  barbell biceps curl    p=0.102\n",
            "  incline bench press    p=0.082\n",
            "  tricep Pushdown        p=0.072\n",
            "\n",
            "=== Angle stats ===\n",
            "{\n",
            "  \"knee_r\": {\n",
            "    \"min\": 151.62733459472656,\n",
            "    \"max\": 180.0,\n",
            "    \"p10\": 156.50329132080077,\n",
            "    \"p90\": 180.0\n",
            "  },\n",
            "  \"knee_l\": {\n",
            "    \"min\": 149.34751892089844,\n",
            "    \"max\": 180.0,\n",
            "    \"p10\": 152.1273162841797,\n",
            "    \"p90\": 180.0\n",
            "  },\n",
            "  \"elbow_r\": {\n",
            "    \"min\": 1.5356959104537964,\n",
            "    \"max\": 180.0,\n",
            "    \"p10\": 47.84908218383789,\n",
            "    \"p90\": 180.0\n",
            "  },\n",
            "  \"elbow_l\": {\n",
            "    \"min\": 45.768863677978516,\n",
            "    \"max\": 180.0,\n",
            "    \"p10\": 76.17696914672852,\n",
            "    \"p90\": 180.0\n",
            "  }\n",
            "}\n",
            "\n",
            "=== Feedback ===\n",
            " - Depth shallow — aim near ~90° knee flexion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u infer_baseline.py \\\n",
        "  --checkpoint /content/best_tcn.pt \\\n",
        "  --cache_dir /content/pose_seq_yolo \\\n",
        "  --video /content/m2-res_640p.mp4 \\\n",
        "  --seq_len 90 --hop 30 \\\n",
        "  --every_n 3 --imgsz 448 --conf 0.25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kE4-G0h-tHN",
        "outputId": "aff28e80-8695-4016-b624-fe500d01af66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] args: {'checkpoint': PosixPath('/content/best_tcn.pt'), 'cache_dir': PosixPath('/content/pose_seq_yolo'), 'npy': None, 'video': PosixPath('/content/m2-res_640p.mp4'), 'seq_len': 90, 'hop': 30, 'device': 'cpu', 'every_n': 3, 'imgsz': 448, 'conf': 0.25, 'batch_size': 32}\n",
            "[info] extracting pose from video (YOLOv8n-pose)...\n",
            "\n",
            "=== Inference (baseline TCN) ===\n",
            "Predicted class: push-up (id=14)\n",
            "  push-up                p=0.383\n",
            "  plank                  p=0.325\n",
            "  decline bench press    p=0.036\n",
            "  romanian deadlift      p=0.028\n",
            "  shoulder press         p=0.022\n",
            "\n",
            "=== Angle stats ===\n",
            "{\n",
            "  \"knee_r\": {\n",
            "    \"min\": 53.70746994018555,\n",
            "    \"max\": 168.45713806152344,\n",
            "    \"p10\": 74.53679809570312,\n",
            "    \"p90\": 139.53519134521486\n",
            "  },\n",
            "  \"knee_l\": {\n",
            "    \"min\": 12.006741523742676,\n",
            "    \"max\": 154.3284912109375,\n",
            "    \"p10\": 49.254337310791016,\n",
            "    \"p90\": 118.75203781127931\n",
            "  },\n",
            "  \"elbow_r\": {\n",
            "    \"min\": 68.95397186279297,\n",
            "    \"max\": 159.97483825683594,\n",
            "    \"p10\": 81.73776321411133,\n",
            "    \"p90\": 154.59338836669923\n",
            "  },\n",
            "  \"elbow_l\": {\n",
            "    \"min\": 9.370811462402344,\n",
            "    \"max\": 178.47695922851562,\n",
            "    \"p10\": 87.47638168334962,\n",
            "    \"p90\": 166.3614730834961\n",
            "  }\n",
            "}\n",
            "\n",
            "=== Feedback ===\n",
            " - Elbows flaring — target ~45° to protect shoulders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u infer_baseline.py \\\n",
        "  --checkpoint /content/best_tcn.pt \\\n",
        "  --cache_dir /content/pose_seq_yolo \\\n",
        "  --video /content/m2-res_640p.mp4 \\\n",
        "  --seq_len 90 --hop 30 \\\n",
        "  --every_n 3 --imgsz 448 --conf 0.25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9hiSieQBcC4",
        "outputId": "56da4ed9-608f-42d1-b7db-fb3b5920caaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] args: {'checkpoint': PosixPath('/content/best_tcn.pt'), 'cache_dir': PosixPath('/content/pose_seq_yolo'), 'npy': None, 'video': PosixPath('/content/m2-res_640p.mp4'), 'seq_len': 90, 'hop': 30, 'device': 'cpu', 'every_n': 3, 'imgsz': 448, 'conf': 0.25, 'batch_size': 32}\n",
            "[info] extracting pose from video (YOLOv8n-pose)...\n",
            "\n",
            "=== Inference (baseline TCN) ===\n",
            "Predicted class: push-up (id=14)\n",
            "  push-up                p=0.383\n",
            "  plank                  p=0.325\n",
            "  decline bench press    p=0.036\n",
            "  romanian deadlift      p=0.028\n",
            "  shoulder press         p=0.022\n",
            "\n",
            "=== Angle stats ===\n",
            "{\n",
            "  \"knee_r\": {\n",
            "    \"min\": 53.70746994018555,\n",
            "    \"max\": 168.45713806152344,\n",
            "    \"p10\": 74.53679809570312,\n",
            "    \"p90\": 139.53519134521486\n",
            "  },\n",
            "  \"knee_l\": {\n",
            "    \"min\": 12.006741523742676,\n",
            "    \"max\": 154.3284912109375,\n",
            "    \"p10\": 49.254337310791016,\n",
            "    \"p90\": 118.75203781127931\n",
            "  },\n",
            "  \"elbow_r\": {\n",
            "    \"min\": 68.95397186279297,\n",
            "    \"max\": 159.97483825683594,\n",
            "    \"p10\": 81.73776321411133,\n",
            "    \"p90\": 154.59338836669923\n",
            "  },\n",
            "  \"elbow_l\": {\n",
            "    \"min\": 9.370811462402344,\n",
            "    \"max\": 178.47695922851562,\n",
            "    \"p10\": 87.47638168334962,\n",
            "    \"p90\": 166.3614730834961\n",
            "  }\n",
            "}\n",
            "\n",
            "=== Feedback ===\n",
            " - Elbows flaring — target ~45° to protect shoulders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==== CONFIG ====\n",
        "CKPT_PATH   = \"/content/best_tcn.pt\"        # your trained baseline TCN\n",
        "CACHE_DIR   = \"/content/pose_seq_yolo\"      # where the .npy sequences live\n",
        "SAVE_ROOT   = \"/content/drive/MyDrive/fitness_form_ai\"  # change if you like\n",
        "\n",
        "# Subfolders in Drive\n",
        "SAVE_MODELS = f\"{SAVE_ROOT}/models\"\n",
        "SAVE_CACHE  = f\"{SAVE_ROOT}/pose_cache\"\n",
        "SAVE_META   = f\"{SAVE_ROOT}/meta\"\n",
        "\n",
        "import os\n",
        "for p in [SAVE_ROOT, SAVE_MODELS, SAVE_CACHE, SAVE_META]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "print(\"Drive folders ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C96ZfFbJK7j5",
        "outputId": "8bdf25a5-a956-42a6-90d5-2b7a640c858e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive folders ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, shutil, hashlib\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "ckpt_src  = Path(CKPT_PATH)\n",
        "cache_src = Path(CACHE_DIR)\n",
        "labels_src = cache_src / \"labels.json\"\n",
        "\n",
        "assert ckpt_src.exists(), f\"Missing checkpoint: {ckpt_src}\"\n",
        "assert cache_src.exists(), f\"Missing cache dir: {cache_src}\"\n",
        "\n",
        "# Copy checkpoint with timestamped name (and also keep a stable name)\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "ckpt_dst1 = Path(SAVE_MODELS) / f\"best_tcn_{stamp}.pt\"\n",
        "ckpt_dst2 = Path(SAVE_MODELS) / \"best_tcn.pt\"   # stable pointer\n",
        "\n",
        "shutil.copy2(ckpt_src, ckpt_dst1)\n",
        "shutil.copy2(ckpt_src, ckpt_dst2)\n",
        "\n",
        "# Copy labels.json (if present)\n",
        "if labels_src.exists():\n",
        "    shutil.copy2(labels_src, Path(SAVE_CACHE) / \"labels.json\")\n",
        "\n",
        "# Copy all .npy pose sequences (skip if already identical)\n",
        "def sha256sum(p):\n",
        "    h = hashlib.sha256()\n",
        "    with open(p, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1024*1024), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "copied = 0\n",
        "skipped = 0\n",
        "for npy in cache_src.glob(\"*.npy\"):\n",
        "    dst = Path(SAVE_CACHE) / npy.name\n",
        "    if dst.exists():\n",
        "        # skip if same content\n",
        "        if sha256sum(npy) == sha256sum(dst):\n",
        "            skipped += 1\n",
        "            continue\n",
        "    shutil.copy2(npy, dst)\n",
        "    copied += 1\n",
        "\n",
        "# Write a manifest with basic info\n",
        "manifest = {\n",
        "    \"saved_at\": stamp,\n",
        "    \"ckpt_dst\": str(ckpt_dst1),\n",
        "    \"ckpt_alias\": str(ckpt_dst2),\n",
        "    \"cache_dir\": str(SAVE_CACHE),\n",
        "    \"counts\": {\n",
        "        \"npy_on_colab\": len(list(cache_src.glob(\"*.npy\"))),\n",
        "        \"npy_on_drive\": len(list(Path(SAVE_CACHE).glob(\"*.npy\")))\n",
        "    }\n",
        "}\n",
        "with open(Path(SAVE_META)/f\"manifest_{stamp}.json\", \"w\") as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "\n",
        "print(f\"Copied: {copied} .npy | Skipped (already identical): {skipped}\")\n",
        "print(f\"Model saved to: {ckpt_dst1} and {ckpt_dst2}\")\n",
        "print(f\"Manifest: {(Path(SAVE_META)/f'manifest_{stamp}.json')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzrrNQzUMtRz",
        "outputId": "f442d7da-2dd8-4a90-e916-7cbb52b957e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Copied: 630 .npy | Skipped (already identical): 0\n",
            "✅ Model saved to: /content/drive/MyDrive/fitness_form_ai/models/best_tcn_20250826-070817.pt and /content/drive/MyDrive/fitness_form_ai/models/best_tcn.pt\n",
            "📄 Manifest: /content/drive/MyDrive/fitness_form_ai/meta/manifest_20250826-070817.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "zip_base = f\"{SAVE_ROOT}/pose_cache_snapshot\"\n",
        "zip_path = shutil.make_archive(zip_base, \"zip\", SAVE_CACHE)\n",
        "print(\"ZIP written:\", zip_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoWATVZ_NMRx",
        "outputId": "2c3c05c7-882b-4cfb-a50f-759de87d74ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZIP written: /content/drive/MyDrive/fitness_form_ai/pose_cache_snapshot.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-x5HlcGNXTG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}